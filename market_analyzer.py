# -*- coding: utf-8 -*-
"""
===================================
å¤§ç›˜å¤ç›˜åˆ†ææ¨¡å—
===================================

èŒè´£ï¼š
1. è·å–å¤§ç›˜æŒ‡æ•°æ•°æ®ï¼ˆä¸Šè¯ã€æ·±è¯ã€åˆ›ä¸šæ¿ï¼‰
2. æœç´¢å¸‚åœºæ–°é—»å½¢æˆå¤ç›˜æƒ…æŠ¥
3. ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆæ¯æ—¥å¤§ç›˜å¤ç›˜æŠ¥å‘Š
"""

import logging
import time
from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional, Dict, Any, List

import akshare as ak
import pandas as pd

from config import get_config
from search_service import SearchService

logger = logging.getLogger(__name__)


@dataclass
class MarketIndex:
    """å¤§ç›˜æŒ‡æ•°æ•°æ®"""
    code: str                    # æŒ‡æ•°ä»£ç 
    name: str                    # æŒ‡æ•°åç§°
    current: float = 0.0         # å½“å‰ç‚¹ä½
    change: float = 0.0          # æ¶¨è·Œç‚¹æ•°
    change_pct: float = 0.0      # æ¶¨è·Œå¹…(%)
    open: float = 0.0            # å¼€ç›˜ç‚¹ä½
    high: float = 0.0            # æœ€é«˜ç‚¹ä½
    low: float = 0.0             # æœ€ä½ç‚¹ä½
    prev_close: float = 0.0      # æ˜¨æ”¶ç‚¹ä½
    volume: float = 0.0          # æˆäº¤é‡ï¼ˆæ‰‹ï¼‰
    amount: float = 0.0          # æˆäº¤é¢ï¼ˆå…ƒï¼‰
    amplitude: float = 0.0       # æŒ¯å¹…(%)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'code': self.code,
            'name': self.name,
            'current': self.current,
            'change': self.change,
            'change_pct': self.change_pct,
            'open': self.open,
            'high': self.high,
            'low': self.low,
            'volume': self.volume,
            'amount': self.amount,
            'amplitude': self.amplitude,
        }


@dataclass
class MarketOverview:
    """å¸‚åœºæ¦‚è§ˆæ•°æ®"""
    date: str                           # æ—¥æœŸ
    indices: List[MarketIndex] = field(default_factory=list)  # ä¸»è¦æŒ‡æ•°
    up_count: int = 0                   # ä¸Šæ¶¨å®¶æ•°
    down_count: int = 0                 # ä¸‹è·Œå®¶æ•°
    flat_count: int = 0                 # å¹³ç›˜å®¶æ•°
    limit_up_count: int = 0             # æ¶¨åœå®¶æ•°
    limit_down_count: int = 0           # è·Œåœå®¶æ•°
    total_amount: float = 0.0           # ä¸¤å¸‚æˆäº¤é¢ï¼ˆäº¿å…ƒï¼‰
    
    # æ¿å—æ¶¨å¹…æ¦œ
    top_sectors: List[Dict] = field(default_factory=list)     # æ¶¨å¹…å‰5æ¿å—
    bottom_sectors: List[Dict] = field(default_factory=list)  # è·Œå¹…å‰5æ¿å—
    
    # ========== å¢å¼ºæ•°æ®ç»´åº¦ ==========
    
    # èèµ„èåˆ¸
    margin_balance: float = 0.0         # èèµ„ä½™é¢ï¼ˆäº¿å…ƒï¼‰
    margin_buy: float = 0.0             # èèµ„ä¹°å…¥é¢ï¼ˆäº¿å…ƒï¼‰
    short_balance: float = 0.0          # èåˆ¸ä½™é¢ï¼ˆäº¿å…ƒï¼‰
    
    # é¾™è™æ¦œ
    lhb_stocks: List[Dict] = field(default_factory=list)      # é¾™è™æ¦œè‚¡ç¥¨
    lhb_net_buy: float = 0.0            # é¾™è™æ¦œå‡€ä¹°å…¥ï¼ˆäº¿å…ƒï¼‰
    lhb_org_buy_count: int = 0          # æœºæ„ä¹°å…¥æ¬¡æ•°
    lhb_org_sell_count: int = 0         # æœºæ„å–å‡ºæ¬¡æ•°
    
    # å¤§å®—äº¤æ˜“
    block_trade_amount: float = 0.0     # å¤§å®—äº¤æ˜“æˆäº¤é¢ï¼ˆäº¿å…ƒï¼‰
    block_trade_premium_ratio: float = 0.0   # æº¢ä»·æˆäº¤å æ¯”(%)
    block_trade_discount_ratio: float = 0.0  # æŠ˜ä»·æˆäº¤å æ¯”(%)
    
    # æ¦‚å¿µæ¿å—çƒ­ç‚¹
    top_concepts: List[Dict] = field(default_factory=list)    # æ¶¨å¹…å‰5æ¦‚å¿µ
    bottom_concepts: List[Dict] = field(default_factory=list) # è·Œå¹…å‰5æ¦‚å¿µ
    
    # å¸‚åœºæƒ…ç»ªæŒ‡æ ‡
    avg_turnover_rate: float = 0.0      # å¹³å‡æ¢æ‰‹ç‡(%)
    high_turnover_count: int = 0        # é«˜æ¢æ‰‹ç‡(>10%)è‚¡ç¥¨æ•°
    new_high_count: int = 0             # åˆ›60æ—¥æ–°é«˜è‚¡ç¥¨æ•°
    new_low_count: int = 0              # åˆ›60æ—¥æ–°ä½è‚¡ç¥¨æ•°
    
    # æ¶¨åœåˆ†æ
    limit_up_broken_count: int = 0      # ç‚¸æ¿æ•°ï¼ˆæ›¾æ¶¨åœåæ‰“å¼€ï¼‰
    continuous_limit_up_count: int = 0  # è¿æ¿è‚¡ç¥¨æ•°
    first_limit_up_count: int = 0       # é¦–æ¿è‚¡ç¥¨æ•°


class MarketAnalyzer:
    """
    å¤§ç›˜å¤ç›˜åˆ†æå™¨
    
    åŠŸèƒ½ï¼š
    1. è·å–å¤§ç›˜æŒ‡æ•°å®æ—¶è¡Œæƒ…
    2. è·å–å¸‚åœºæ¶¨è·Œç»Ÿè®¡
    3. è·å–æ¿å—æ¶¨è·Œæ¦œ
    4. è·å–åŒ—å‘èµ„é‡‘æµå‘
    5. è·å–èèµ„èåˆ¸æ•°æ®
    6. è·å–é¾™è™æ¦œæ•°æ®
    7. è·å–å¤§å®—äº¤æ˜“æ•°æ®
    8. è·å–æ¦‚å¿µæ¿å—çƒ­ç‚¹
    9. æœç´¢å¸‚åœºæ–°é—»
    10. ç”Ÿæˆå¤§ç›˜å¤ç›˜æŠ¥å‘Š
    """
    
    # ä¸»è¦æŒ‡æ•°ä»£ç 
    MAIN_INDICES = {
        'sh000001': 'ä¸Šè¯æŒ‡æ•°',
        'sz399001': 'æ·±è¯æˆæŒ‡',
        'sz399006': 'åˆ›ä¸šæ¿æŒ‡',
        'sh000688': 'ç§‘åˆ›50',
        'sh000016': 'ä¸Šè¯50',
        'sh000300': 'æ²ªæ·±300',
        'sh000015': 'çº¢åˆ©æŒ‡æ•°',
        'sh000905': 'ä¸­è¯500',
        'sh000906': 'ä¸­è¯800',
        'sz399012': 'åˆ›ä¸š300',
        'sz399303': 'å›½è¯2000',
        'sz399372': 'å¤§ç›˜æˆé•¿',
        'sz399373': 'å¤§ç›˜ä»·å€¼',
        'sz399374': 'ä¸­ç›˜æˆé•¿',
        'sz399375': 'ä¸­ç›˜ä»·å€¼',
        'sz399376': 'å°ç›˜æˆé•¿',
        'sz399377': 'å°ç›˜ä»·å€¼'
    }
    
    def __init__(self, search_service: Optional[SearchService] = None, analyzer=None):
        """
        åˆå§‹åŒ–å¤§ç›˜åˆ†æå™¨
        
        Args:
            search_service: æœç´¢æœåŠ¡å®ä¾‹
            analyzer: AIåˆ†æå™¨å®ä¾‹ï¼ˆç”¨äºè°ƒç”¨LLMï¼‰
        """
        self.config = get_config()
        self.search_service = search_service
        self.analyzer = analyzer
        
    def get_market_overview(self, target_date: Optional[str] = None) -> MarketOverview:
        """
        è·å–å¸‚åœºæ¦‚è§ˆæ•°æ®ï¼ˆå¢å¼ºç‰ˆï¼Œæ”¯æŒæŒ‡å®šæ—¥æœŸï¼‰
        
        Args:
            target_date: ç›®æ ‡æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'ï¼Œé»˜è®¤ä¸ºä»Šå¤©
            
        Returns:
            MarketOverview: å¸‚åœºæ¦‚è§ˆæ•°æ®å¯¹è±¡
        """
        if target_date is None:
            target_date = datetime.now().strftime('%Y-%m-%d')
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºå†å²æ—¥æœŸ
        is_historical = target_date != datetime.now().strftime('%Y-%m-%d')
        
        overview = MarketOverview(date=target_date)
        
        if is_historical:
            logger.info(f"[å¤§ç›˜] è·å–å†å²æ•°æ®: {target_date}")
            # å†å²æ•°æ®æ¨¡å¼
            overview.indices = self._get_main_indices_hist(target_date)
            self._get_market_statistics_hist(overview, target_date)
        else:
            # å®æ—¶æ•°æ®æ¨¡å¼
            overview.indices = self._get_main_indices()
            self._get_market_statistics(overview)
        
        # ä»¥ä¸‹æ•°æ®æ”¯æŒå†å²æŸ¥è¯¢
        self._get_sector_rankings(overview)
        self._get_concept_rankings(overview)
        self._get_margin_data(overview, target_date)
        self._get_lhb_data(overview, target_date)
        self._get_block_trade_data(overview)
        
        return overview

    def _call_akshare_with_retry(self, fn, name: str, attempts: int = 2):
        last_error: Optional[Exception] = None
        for attempt in range(1, attempts + 1):
            try:
                return fn()
            except Exception as e:
                last_error = e
                logger.warning(f"[å¤§ç›˜] {name} è·å–å¤±è´¥ (attempt {attempt}/{attempts}): {e}")
                if attempt < attempts:
                    time.sleep(min(2 ** attempt, 5))
        logger.error(f"[å¤§ç›˜] {name} æœ€ç»ˆå¤±è´¥: {last_error}")
        return None
    
    def _get_main_indices(self) -> List[MarketIndex]:
        """è·å–ä¸»è¦æŒ‡æ•°å®æ—¶è¡Œæƒ…"""
        indices = []
        
        try:
            logger.info("[å¤§ç›˜] è·å–ä¸»è¦æŒ‡æ•°å®æ—¶è¡Œæƒ…...")
            
            # ä½¿ç”¨ akshare è·å–æŒ‡æ•°è¡Œæƒ…ï¼ˆæ–°æµªè´¢ç»æ¥å£ï¼ŒåŒ…å«æ·±å¸‚æŒ‡æ•°ï¼‰
            df = self._call_akshare_with_retry(ak.stock_zh_index_spot_sina, "æŒ‡æ•°è¡Œæƒ…", attempts=2)
            
            if df is not None and not df.empty:
                for code, name in self.MAIN_INDICES.items():
                    # æŸ¥æ‰¾å¯¹åº”æŒ‡æ•°
                    row = df[df['ä»£ç '] == code]
                    if row.empty:
                        # å°è¯•å¸¦å‰ç¼€æŸ¥æ‰¾
                        row = df[df['ä»£ç '].str.contains(code)]
                    
                    if not row.empty:
                        row = row.iloc[0]
                        index = MarketIndex(
                            code=code,
                            name=name,
                            current=float(row.get('æœ€æ–°ä»·', 0) or 0),
                            change=float(row.get('æ¶¨è·Œé¢', 0) or 0),
                            change_pct=float(row.get('æ¶¨è·Œå¹…', 0) or 0),
                            open=float(row.get('ä»Šå¼€', 0) or 0),
                            high=float(row.get('æœ€é«˜', 0) or 0),
                            low=float(row.get('æœ€ä½', 0) or 0),
                            prev_close=float(row.get('æ˜¨æ”¶', 0) or 0),
                            volume=float(row.get('æˆäº¤é‡', 0) or 0),
                            amount=float(row.get('æˆäº¤é¢', 0) or 0),
                        )
                        # è®¡ç®—æŒ¯å¹…
                        if index.prev_close > 0:
                            index.amplitude = (index.high - index.low) / index.prev_close * 100
                        indices.append(index)
                        
                logger.info(f"[å¤§ç›˜] è·å–åˆ° {len(indices)} ä¸ªæŒ‡æ•°è¡Œæƒ…")
                
        except Exception as e:
            logger.error(f"[å¤§ç›˜] è·å–æŒ‡æ•°è¡Œæƒ…å¤±è´¥: {e}")
        
        return indices
    
    def _get_main_indices_hist(self, target_date: str) -> List[MarketIndex]:
        """è·å–ä¸»è¦æŒ‡æ•°å†å²è¡Œæƒ…"""
        indices = []
        
        try:
            logger.info(f"[å¤§ç›˜] è·å–æŒ‡æ•°å†å²è¡Œæƒ…: {target_date}...")
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            date_str = target_date.replace('-', '')
            
            for code, name in self.MAIN_INDICES.items():
                try:
                    # ä½¿ç”¨ index_zh_a_hist è·å–å†å²æ•°æ®
                    # ä»£ç æ ¼å¼éœ€è¦è½¬æ¢ï¼šsh000001 -> 000001
                    symbol = code[2:] if code.startswith(('sh', 'sz')) else code
                    
                    df = ak.index_zh_a_hist(
                        symbol=symbol,
                        period="daily",
                        start_date=date_str,
                        end_date=date_str
                    )
                    
                    if df is not None and not df.empty:
                        row = df.iloc[0]
                        index = MarketIndex(
                            code=code,
                            name=name,
                            current=float(row.get('æ”¶ç›˜', 0) or 0),
                            change=float(row.get('æ”¶ç›˜', 0) or 0) - float(row.get('å¼€ç›˜', 0) or 0),
                            change_pct=float(row.get('æ¶¨è·Œå¹…', 0) or 0),
                            open=float(row.get('å¼€ç›˜', 0) or 0),
                            high=float(row.get('æœ€é«˜', 0) or 0),
                            low=float(row.get('æœ€ä½', 0) or 0),
                            volume=float(row.get('æˆäº¤é‡', 0) or 0),
                            amount=float(row.get('æˆäº¤é¢', 0) or 0),
                        )
                        # è®¡ç®—æŒ¯å¹…
                        if index.open > 0:
                            index.amplitude = (index.high - index.low) / index.open * 100
                        indices.append(index)
                        
                except Exception as e:
                    logger.warning(f"[å¤§ç›˜] è·å– {name} å†å²æ•°æ®å¤±è´¥: {e}")
                    continue
                    
            logger.info(f"[å¤§ç›˜] è·å–åˆ° {len(indices)} ä¸ªæŒ‡æ•°å†å²è¡Œæƒ…")
                
        except Exception as e:
            logger.error(f"[å¤§ç›˜] è·å–æŒ‡æ•°å†å²è¡Œæƒ…å¤±è´¥: {e}")
        
        return indices
    
    def _get_market_statistics_hist(self, overview: MarketOverview, target_date: str):
        """è·å–å†å²å¸‚åœºæ¶¨è·Œç»Ÿè®¡ï¼ˆç®€åŒ–ç‰ˆï¼Œéƒ¨åˆ†æ•°æ®ä¸å¯ç”¨ï¼‰"""
        try:
            logger.info(f"[å¤§ç›˜] è·å–å†å²æ¶¨è·Œç»Ÿè®¡: {target_date}...")
            
            # å†å²æ•°æ®æ¨¡å¼ä¸‹ï¼Œéƒ¨åˆ†å®æ—¶æ•°æ®ä¸å¯ç”¨
            # å¯ä»¥ä»æŒ‡æ•°æˆäº¤é¢ä¼°ç®—ä¸¤å¸‚æˆäº¤é¢
            total_amount = 0.0
            for idx in overview.indices:
                if idx.code in ['sh000001', 'sz399001']:  # ä¸Šè¯+æ·±è¯
                    total_amount += idx.amount / 1e8  # è½¬ä¸ºäº¿å…ƒ
            
            overview.total_amount = total_amount
            
            logger.info(f"[å¤§ç›˜] å†å²æˆäº¤é¢(ä¼°ç®—): {overview.total_amount:.0f}äº¿")
            logger.warning("[å¤§ç›˜] å†å²æ¨¡å¼ä¸‹æ¶¨è·Œå®¶æ•°ç­‰æ•°æ®ä¸å¯ç”¨")
                
        except Exception as e:
            logger.error(f"[å¤§ç›˜] è·å–å†å²æ¶¨è·Œç»Ÿè®¡å¤±è´¥: {e}")
    
    def _get_market_statistics(self, overview: MarketOverview):
        """è·å–å¸‚åœºæ¶¨è·Œç»Ÿè®¡ï¼ˆå«æƒ…ç»ªæŒ‡æ ‡ï¼‰"""
        try:
            logger.info("[å¤§ç›˜] è·å–å¸‚åœºæ¶¨è·Œç»Ÿè®¡...")
            
            # è·å–å…¨éƒ¨Aè‚¡å®æ—¶è¡Œæƒ…
            df = self._call_akshare_with_retry(ak.stock_zh_a_spot_em, "Aè‚¡å®æ—¶è¡Œæƒ…", attempts=2)
            
            if df is not None and not df.empty:
                # æ¶¨è·Œç»Ÿè®¡
                change_col = 'æ¶¨è·Œå¹…'
                if change_col in df.columns:
                    df[change_col] = pd.to_numeric(df[change_col], errors='coerce')
                    overview.up_count = len(df[df[change_col] > 0])
                    overview.down_count = len(df[df[change_col] < 0])
                    overview.flat_count = len(df[df[change_col] == 0])
                    
                    # æ¶¨åœè·Œåœç»Ÿè®¡ï¼ˆæ¶¨è·Œå¹… >= 9.9% æˆ– <= -9.9%ï¼‰
                    overview.limit_up_count = len(df[df[change_col] >= 9.9])
                    overview.limit_down_count = len(df[df[change_col] <= -9.9])
                
                # ä¸¤å¸‚æˆäº¤é¢
                amount_col = 'æˆäº¤é¢'
                if amount_col in df.columns:
                    df[amount_col] = pd.to_numeric(df[amount_col], errors='coerce')
                    overview.total_amount = df[amount_col].sum() / 1e8  # è½¬ä¸ºäº¿å…ƒ
                
                # ========== æƒ…ç»ªæŒ‡æ ‡ ==========
                
                # å¹³å‡æ¢æ‰‹ç‡
                turnover_col = 'æ¢æ‰‹ç‡'
                if turnover_col in df.columns:
                    df[turnover_col] = pd.to_numeric(df[turnover_col], errors='coerce')
                    overview.avg_turnover_rate = df[turnover_col].mean()
                    # é«˜æ¢æ‰‹ç‡è‚¡ç¥¨æ•°ï¼ˆ>10%ï¼‰
                    overview.high_turnover_count = len(df[df[turnover_col] > 10])
                
                # åˆ›60æ—¥æ–°é«˜/æ–°ä½
                change_60d_col = '60æ—¥æ¶¨è·Œå¹…'
                high_col = 'æœ€é«˜'
                low_col = 'æœ€ä½'
                if change_60d_col in df.columns:
                    df[change_60d_col] = pd.to_numeric(df[change_60d_col], errors='coerce')
                    # ç®€åŒ–åˆ¤æ–­ï¼š60æ—¥æ¶¨å¹…>30%ä¸”ä»Šæ—¥åˆ›æ–°é«˜
                    overview.new_high_count = len(df[(df[change_60d_col] > 30) & (df[change_col] > 3)])
                    # 60æ—¥è·Œå¹…>30%ä¸”ä»Šæ—¥åˆ›æ–°ä½
                    overview.new_low_count = len(df[(df[change_60d_col] < -30) & (df[change_col] < -3)])
                
                logger.info(f"[å¤§ç›˜] æ¶¨:{overview.up_count} è·Œ:{overview.down_count} å¹³:{overview.flat_count} "
                          f"æ¶¨åœ:{overview.limit_up_count} è·Œåœ:{overview.limit_down_count} "
                          f"æˆäº¤é¢:{overview.total_amount:.0f}äº¿ "
                          f"å¹³å‡æ¢æ‰‹:{overview.avg_turnover_rate:.2f}%")
                
        except Exception as e:
            logger.error(f"[å¤§ç›˜] è·å–æ¶¨è·Œç»Ÿè®¡å¤±è´¥: {e}")
    
    def _get_sector_rankings(self, overview: MarketOverview):
        """è·å–æ¿å—æ¶¨è·Œæ¦œ"""
        try:
            logger.info("[å¤§ç›˜] è·å–æ¿å—æ¶¨è·Œæ¦œ...")
            
            # è·å–è¡Œä¸šæ¿å—è¡Œæƒ…
            df = self._call_akshare_with_retry(ak.stock_board_industry_name_em, "è¡Œä¸šæ¿å—è¡Œæƒ…", attempts=2)
            
            if df is not None and not df.empty:
                change_col = 'æ¶¨è·Œå¹…'
                if change_col in df.columns:
                    df[change_col] = pd.to_numeric(df[change_col], errors='coerce')
                    df = df.dropna(subset=[change_col])
                    
                    # æ¶¨å¹…å‰5
                    top = df.nlargest(5, change_col)
                    overview.top_sectors = [
                        {'name': row['æ¿å—åç§°'], 'change_pct': row[change_col]}
                        for _, row in top.iterrows()
                    ]
                    
                    # è·Œå¹…å‰5
                    bottom = df.nsmallest(5, change_col)
                    overview.bottom_sectors = [
                        {'name': row['æ¿å—åç§°'], 'change_pct': row[change_col]}
                        for _, row in bottom.iterrows()
                    ]
                    
                    logger.info(f"[å¤§ç›˜] é¢†æ¶¨æ¿å—: {[s['name'] for s in overview.top_sectors]}")
                    logger.info(f"[å¤§ç›˜] é¢†è·Œæ¿å—: {[s['name'] for s in overview.bottom_sectors]}")
                    
        except Exception as e:
            logger.error(f"[å¤§ç›˜] è·å–æ¿å—æ¶¨è·Œæ¦œå¤±è´¥: {e}")
    
    def _get_concept_rankings(self, overview: MarketOverview):
        """è·å–æ¦‚å¿µæ¿å—çƒ­ç‚¹"""
        try:
            logger.info("[å¤§ç›˜] è·å–æ¦‚å¿µæ¿å—çƒ­ç‚¹...")
            
            # è·å–æ¦‚å¿µæ¿å—è¡Œæƒ…
            df = self._call_akshare_with_retry(ak.stock_board_concept_name_em, "æ¦‚å¿µæ¿å—è¡Œæƒ…", attempts=2)
            
            if df is not None and not df.empty:
                change_col = 'æ¶¨è·Œå¹…'
                if change_col in df.columns:
                    df[change_col] = pd.to_numeric(df[change_col], errors='coerce')
                    df = df.dropna(subset=[change_col])
                    
                    # æ¶¨å¹…å‰5æ¦‚å¿µ
                    top = df.nlargest(5, change_col)
                    overview.top_concepts = [
                        {'name': row['æ¿å—åç§°'], 'change_pct': row[change_col]}
                        for _, row in top.iterrows()
                    ]
                    
                    # è·Œå¹…å‰5æ¦‚å¿µ
                    bottom = df.nsmallest(5, change_col)
                    overview.bottom_concepts = [
                        {'name': row['æ¿å—åç§°'], 'change_pct': row[change_col]}
                        for _, row in bottom.iterrows()
                    ]
                    
                    logger.info(f"[å¤§ç›˜] çƒ­é—¨æ¦‚å¿µ: {[s['name'] for s in overview.top_concepts]}")
                    
        except Exception as e:
            logger.error(f"[å¤§ç›˜] è·å–æ¦‚å¿µæ¿å—å¤±è´¥: {e}")
    
    def _get_margin_data(self, overview: MarketOverview, target_date: Optional[str] = None):
        """è·å–èèµ„èåˆ¸æ•°æ®"""
        try:
            logger.info("[å¤§ç›˜] è·å–èèµ„èåˆ¸æ•°æ®...")
            
            # è·å–ä¸¤èè´¦æˆ·ä¿¡æ¯
            df = self._call_akshare_with_retry(ak.stock_margin_account_info, "èèµ„èåˆ¸", attempts=2)
            
            if df is not None and not df.empty:
                # å¦‚æœæŒ‡å®šäº†æ—¥æœŸï¼Œå°è¯•æ‰¾åˆ°å¯¹åº”æ—¥æœŸçš„æ•°æ®
                if target_date and 'æ—¥æœŸ' in df.columns:
                    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
                    date_match = df[df['æ—¥æœŸ'] == target_date]
                    if not date_match.empty:
                        latest = date_match.iloc[0]
                    else:
                        # æ‰¾ä¸åˆ°æŒ‡å®šæ—¥æœŸï¼Œä½¿ç”¨æœ€è¿‘çš„æ•°æ®
                        latest = df.iloc[-1]
                        logger.warning(f"[å¤§ç›˜] æœªæ‰¾åˆ° {target_date} çš„èèµ„èåˆ¸æ•°æ®ï¼Œä½¿ç”¨æœ€æ–°æ•°æ®")
                else:
                    latest = df.iloc[-1]
                
                # èèµ„ä½™é¢ï¼ˆäº¿å…ƒï¼‰
                if 'èèµ„ä½™é¢' in df.columns:
                    overview.margin_balance = float(latest.get('èèµ„ä½™é¢', 0) or 0)
                # èèµ„ä¹°å…¥é¢ï¼ˆäº¿å…ƒï¼‰
                if 'èèµ„ä¹°å…¥é¢' in df.columns:
                    overview.margin_buy = float(latest.get('èèµ„ä¹°å…¥é¢', 0) or 0)
                # èåˆ¸ä½™é¢ï¼ˆäº¿å…ƒï¼‰
                if 'èåˆ¸ä½™é¢' in df.columns:
                    overview.short_balance = float(latest.get('èåˆ¸ä½™é¢', 0) or 0)
                
                logger.info(f"[å¤§ç›˜] èèµ„ä½™é¢: {overview.margin_balance:.0f}äº¿ "
                          f"èèµ„ä¹°å…¥: {overview.margin_buy:.2f}äº¿ èåˆ¸ä½™é¢: {overview.short_balance:.2f}äº¿")
                
        except Exception as e:
            logger.warning(f"[å¤§ç›˜] è·å–èèµ„èåˆ¸æ•°æ®å¤±è´¥: {e}")
    
    def _get_lhb_data(self, overview: MarketOverview, target_date: Optional[str] = None):
        """
        è·å–é¾™è™æ¦œæ•°æ®
        
        æ³¨æ„ï¼šé¾™è™æ¦œæ•°æ®é€šå¸¸åœ¨æ”¶ç›˜åæ‰æ›´æ–°ï¼Œå½“å¤©æ•°æ®å¯èƒ½ä¸å¯ç”¨
        å¦‚æœå½“å¤©æ•°æ®è·å–å¤±è´¥ï¼Œä¼šè‡ªåŠ¨å°è¯•è·å–å‰å‡ ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
        """
        try:
            logger.info("[å¤§ç›˜] è·å–é¾™è™æ¦œæ•°æ®...")
            
            # ä½¿ç”¨æŒ‡å®šæ—¥æœŸæˆ–ä»Šå¤©
            if target_date:
                base_date = datetime.strptime(target_date, '%Y-%m-%d')
            else:
                base_date = datetime.now()
            
            df = None
            actual_date = None
            
            # å°è¯•è·å–æœ€è¿‘å‡ å¤©çš„æ•°æ®ï¼ˆå½“å¤©æ•°æ®å¯èƒ½è¿˜æ²¡æ›´æ–°ï¼‰
            for days_ago in range(0, 5):
                try_date = base_date - pd.Timedelta(days=days_ago)
                date_str = try_date.strftime('%Y%m%d')
                
                try:
                    df = ak.stock_lhb_detail_em(start_date=date_str, end_date=date_str)
                    if df is not None and not df.empty:
                        actual_date = try_date.strftime('%Y-%m-%d')
                        if days_ago > 0:
                            logger.info(f"[å¤§ç›˜] ä½¿ç”¨ {actual_date} çš„é¾™è™æ¦œæ•°æ®ï¼ˆ{days_ago}å¤©å‰ï¼‰")
                        break
                except Exception as e:
                    if days_ago == 0:
                        logger.debug(f"[å¤§ç›˜] å½“å¤©é¾™è™æ¦œæ•°æ®æš‚ä¸å¯ç”¨: {e}")
                    continue
            
            if df is not None and not df.empty:
                # é¾™è™æ¦œè‚¡ç¥¨åˆ—è¡¨
                overview.lhb_stocks = []
                for _, row in df.head(10).iterrows():
                    overview.lhb_stocks.append({
                        'code': row.get('ä»£ç ', ''),
                        'name': row.get('åç§°', ''),
                        'change_pct': float(row.get('æ¶¨è·Œå¹…', 0) or 0),
                        'net_buy': float(row.get('é¾™è™æ¦œå‡€ä¹°é¢', 0) or 0) / 1e8,  # è½¬ä¸ºäº¿å…ƒ
                        'reason': row.get('ä¸Šæ¦œåŸå› ', ''),
                    })
                
                # é¾™è™æ¦œå‡€ä¹°å…¥æ€»é¢
                if 'é¾™è™æ¦œå‡€ä¹°é¢' in df.columns:
                    df['é¾™è™æ¦œå‡€ä¹°é¢'] = pd.to_numeric(df['é¾™è™æ¦œå‡€ä¹°é¢'], errors='coerce')
                    overview.lhb_net_buy = df['é¾™è™æ¦œå‡€ä¹°é¢'].sum() / 1e8
                
                logger.info(f"[å¤§ç›˜] é¾™è™æ¦œ({actual_date}): {len(df)}åªè‚¡ç¥¨ä¸Šæ¦œ, å‡€ä¹°å…¥: {overview.lhb_net_buy:.2f}äº¿")
            else:
                logger.warning("[å¤§ç›˜] æœªèƒ½è·å–åˆ°é¾™è™æ¦œæ•°æ®")
                
        except Exception as e:
            logger.warning(f"[å¤§ç›˜] è·å–é¾™è™æ¦œæ•°æ®å¤±è´¥: {e}")
    
    def _get_block_trade_data(self, overview: MarketOverview):
        """è·å–å¤§å®—äº¤æ˜“æ•°æ®"""
        try:
            logger.info("[å¤§ç›˜] è·å–å¤§å®—äº¤æ˜“æ•°æ®...")
            
            # è·å–å¤§å®—äº¤æ˜“å¸‚åœºç»Ÿè®¡
            df = self._call_akshare_with_retry(ak.stock_dzjy_sctj, "å¤§å®—äº¤æ˜“", attempts=2)
            
            if df is not None and not df.empty:
                # å–æœ€æ–°ä¸€æ¡æ•°æ®
                latest = df.iloc[0]  # æŒ‰æ—¥æœŸé™åºï¼Œç¬¬ä¸€æ¡æ˜¯æœ€æ–°
                
                # å¤§å®—äº¤æ˜“æˆäº¤é¢ï¼ˆå…ƒè½¬äº¿å…ƒï¼‰
                if 'å¤§å®—äº¤æ˜“æˆäº¤æ€»é¢' in df.columns:
                    overview.block_trade_amount = float(latest.get('å¤§å®—äº¤æ˜“æˆäº¤æ€»é¢', 0) or 0) / 1e8
                # æº¢ä»·æˆäº¤å æ¯”
                if 'æº¢ä»·æˆäº¤æ€»é¢å æ¯”' in df.columns:
                    overview.block_trade_premium_ratio = float(latest.get('æº¢ä»·æˆäº¤æ€»é¢å æ¯”', 0) or 0)
                # æŠ˜ä»·æˆäº¤å æ¯”
                if 'æŠ˜ä»·æˆäº¤æ€»é¢å æ¯”' in df.columns:
                    overview.block_trade_discount_ratio = float(latest.get('æŠ˜ä»·æˆäº¤æ€»é¢å æ¯”', 0) or 0)
                
                logger.info(f"[å¤§ç›˜] å¤§å®—äº¤æ˜“: {overview.block_trade_amount:.2f}äº¿ "
                          f"æº¢ä»·å æ¯”:{overview.block_trade_premium_ratio:.1f}% "
                          f"æŠ˜ä»·å æ¯”:{overview.block_trade_discount_ratio:.1f}%")
                
        except Exception as e:
            logger.warning(f"[å¤§ç›˜] è·å–å¤§å®—äº¤æ˜“æ•°æ®å¤±è´¥: {e}")

    
    def search_market_news(self, use_smart_search: bool = True) -> List[Dict]:
        """
        æœç´¢å¸‚åœºæ–°é—»
        
        Args:
            use_smart_search: æ˜¯å¦ä½¿ç”¨ LLM æ™ºèƒ½æœç´¢ä¼˜åŒ–
        
        Returns:
            æ–°é—»åˆ—è¡¨
        """
        if not self.search_service:
            logger.warning("[å¤§ç›˜] æœç´¢æœåŠ¡æœªé…ç½®ï¼Œè·³è¿‡æ–°é—»æœç´¢")
            return []
        
        all_news = []
        today = datetime.now()
        month_str = f"{today.year}å¹´{today.month}æœˆ"
        
        # å°è¯•ä½¿ç”¨ LLM ç”Ÿæˆæ™ºèƒ½æœç´¢è¯
        search_queries = None
        
        if use_smart_search and self.analyzer and self.analyzer.is_available():
            try:
                search_queries = self._generate_market_search_queries()
                if search_queries:
                    logger.info(f"[å¤§ç›˜] ä½¿ç”¨ LLM ç”Ÿæˆçš„æ™ºèƒ½æœç´¢è¯: {search_queries}")
            except Exception as e:
                logger.warning(f"[å¤§ç›˜] LLM ç”Ÿæˆæœç´¢è¯å¤±è´¥: {e}")
        
        # å¦‚æœæ™ºèƒ½æœç´¢å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æœç´¢è¯
        if not search_queries:
            search_queries = [
                f"Aè‚¡ å¤§ç›˜ å¤ç›˜ {month_str}",
                f"è‚¡å¸‚ è¡Œæƒ… åˆ†æ ä»Šæ—¥ {month_str}",
                f"Aè‚¡ å¸‚åœº çƒ­ç‚¹ æ¿å— {month_str}",
            ]
        
        try:
            logger.info("[å¤§ç›˜] å¼€å§‹æœç´¢å¸‚åœºæ–°é—»...")
            
            for query in search_queries:
                # ä½¿ç”¨ custom_query ç›´æ¥ä¼ é€’å®Œæ•´çš„æœç´¢è¯
                response = self.search_service.search_stock_news(
                    stock_code="market",
                    stock_name="å¤§ç›˜",
                    max_results=3,
                    custom_query=query  # ç›´æ¥ä½¿ç”¨å®Œæ•´çš„æœç´¢è¯
                )
                if response and response.results:
                    all_news.extend(response.results)
                    logger.info(f"[å¤§ç›˜] æœç´¢ '{query}' è·å– {len(response.results)} æ¡ç»“æœ")
            
            logger.info(f"[å¤§ç›˜] å…±è·å– {len(all_news)} æ¡å¸‚åœºæ–°é—»")
            
        except Exception as e:
            logger.error(f"[å¤§ç›˜] æœç´¢å¸‚åœºæ–°é—»å¤±è´¥: {e}")
        
        return all_news
    
    def _generate_market_search_queries(self) -> Optional[List[str]]:
        """
        ä½¿ç”¨ LLM ç”Ÿæˆå¤§ç›˜åˆ†æçš„æ™ºèƒ½æœç´¢è¯
        
        Returns:
            æœç´¢è¯åˆ—è¡¨ï¼Œå¤±è´¥è¿”å› None
        """
        if not self.analyzer or not self.analyzer.is_available():
            return None
        
        current_date = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        current_month = datetime.now().strftime('%Yå¹´%mæœˆ')
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„Aè‚¡å¸‚åœºåˆ†æå¸ˆï¼Œè¯·ä¸ºä»Šæ—¥å¤§ç›˜å¤ç›˜ç”Ÿæˆç²¾å‡†çš„æœç´¢å…³é”®è¯ã€‚

## ä»»åŠ¡
ç”Ÿæˆç”¨äºæœç´¢ä»Šæ—¥Aè‚¡å¸‚åœºæ–°é—»å’Œåˆ†æçš„å…³é”®è¯

## å½“å‰æ—¥æœŸ
{current_date}

## æœç´¢ç›®çš„
1. è·å–ä»Šæ—¥å¤§ç›˜èµ°åŠ¿åˆ†æ
2. äº†è§£å¸‚åœºçƒ­ç‚¹æ¿å—å’Œæ¦‚å¿µ
3. è·å–é‡è¦æ”¿ç­–å’Œæ¶ˆæ¯é¢ä¿¡æ¯
4. äº†è§£èµ„é‡‘æµå‘å’Œå¸‚åœºæƒ…ç»ª

## è¦æ±‚
1. ç”Ÿæˆ 4-5 ä¸ªæœç´¢å…³é”®è¯/çŸ­è¯­
2. å…³é”®è¯è¦å…·ä½“ã€ç²¾å‡†ï¼Œèƒ½æœç´¢åˆ°æœ‰ä»·å€¼çš„å¸‚åœºä¿¡æ¯
3. åŒ…å«æ—¶é—´é™å®šè¯ï¼ˆå¦‚"{current_month}"ã€"ä»Šæ—¥"ã€"æœ€æ–°"ï¼‰
4. è¦†ç›–ä¸åŒç»´åº¦ï¼šå¤§ç›˜èµ°åŠ¿ã€æ¿å—çƒ­ç‚¹ã€æ”¿ç­–æ¶ˆæ¯ã€èµ„é‡‘åŠ¨å‘

## è¾“å‡ºæ ¼å¼
è¯·ç›´æ¥è¾“å‡ºæœç´¢å…³é”®è¯ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦ç¼–å·ï¼Œä¸è¦è§£é‡Šï¼š

ç¤ºä¾‹è¾“å‡ºï¼š
Aè‚¡ å¤§ç›˜ ä»Šæ—¥ èµ°åŠ¿åˆ†æ
è‚¡å¸‚ çƒ­ç‚¹æ¿å— {current_month}
Aè‚¡ æ”¿ç­– åˆ©å¥½ æœ€æ–°æ¶ˆæ¯
å¸‚åœº èµ„é‡‘æµå‘ ä¸»åŠ›åŠ¨å‘
"""
        
        try:
            generation_config = {
                'temperature': 0.3,
                'max_output_tokens': 300,
            }
            
            response = self.analyzer._call_openai_api(prompt, generation_config)
            
            if not response:
                return None
            
            # è§£ææœç´¢è¯
            queries = []
            for line in response.strip().split('\n'):
                line = line.strip()
                if line and not line.startswith('#') and not line.startswith('ç¤ºä¾‹'):
                    # ç§»é™¤å¯èƒ½çš„ç¼–å·
                    if line[0].isdigit() and '.' in line[:3]:
                        line = line.split('.', 1)[1].strip()
                    if line:
                        queries.append(line)
            
            return queries[:5] if queries else None
            
        except Exception as e:
            logger.warning(f"[å¤§ç›˜] LLM ç”Ÿæˆæœç´¢è¯å¼‚å¸¸: {e}")
            return None
    
    def generate_market_review(self, overview: MarketOverview, news: List) -> str:
        """
        ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆå¤§ç›˜å¤ç›˜æŠ¥å‘Š
        
        Args:
            overview: å¸‚åœºæ¦‚è§ˆæ•°æ®
            news: å¸‚åœºæ–°é—»åˆ—è¡¨ (SearchResult å¯¹è±¡åˆ—è¡¨)
            
        Returns:
            å¤§ç›˜å¤ç›˜æŠ¥å‘Šæ–‡æœ¬
        """
        if not self.analyzer or not self.analyzer.is_available():
            logger.warning("[å¤§ç›˜] AIåˆ†æå™¨æœªé…ç½®æˆ–ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ¿ç”ŸæˆæŠ¥å‘Š")
            return self._generate_template_review(overview, news)
        
        # æ„å»º Prompt
        prompt = self._build_review_prompt(overview, news)
        
        try:
            logger.info("[å¤§ç›˜] è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå¤ç›˜æŠ¥å‘Š...")
            
            generation_config = {
                'temperature': 0.7,
            }
            
            # ä½¿ç”¨ OpenAI å…¼å®¹ API
            review = self.analyzer._call_openai_api(prompt, generation_config)
            
            if review:
                logger.info(f"[å¤§ç›˜] å¤ç›˜æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(review)} å­—ç¬¦")
                return review
            else:
                logger.warning("[å¤§ç›˜] å¤§æ¨¡å‹è¿”å›ä¸ºç©º")
                return self._generate_template_review(overview, news)
                
        except Exception as e:
            logger.error(f"[å¤§ç›˜] å¤§æ¨¡å‹ç”Ÿæˆå¤ç›˜æŠ¥å‘Šå¤±è´¥: {e}")
            return self._generate_template_review(overview, news)
    
    def _build_review_prompt(self, overview: MarketOverview, news: List) -> str:
        """æ„å»ºå¤ç›˜æŠ¥å‘Š Promptï¼ˆå¢å¼ºç‰ˆï¼ŒåŒ…å«å¤šç»´åº¦æ•°æ®ï¼‰"""
        # æŒ‡æ•°è¡Œæƒ…ä¿¡æ¯
        indices_text = ""
        for idx in overview.indices:
            direction = "â†‘" if idx.change_pct > 0 else "â†“" if idx.change_pct < 0 else "-"
            indices_text += f"- {idx.name}: {idx.current:.2f} ({direction}{abs(idx.change_pct):.2f}%)\n"
        
        # è¡Œä¸šæ¿å—ä¿¡æ¯
        top_sectors_text = ", ".join([f"{s['name']}({s['change_pct']:+.2f}%)" for s in overview.top_sectors[:5]])
        bottom_sectors_text = ", ".join([f"{s['name']}({s['change_pct']:+.2f}%)" for s in overview.bottom_sectors[:5]])
        
        # æ¦‚å¿µæ¿å—ä¿¡æ¯
        top_concepts_text = ", ".join([f"{s['name']}({s['change_pct']:+.2f}%)" for s in overview.top_concepts[:5]]) if overview.top_concepts else "æš‚æ— æ•°æ®"
        bottom_concepts_text = ", ".join([f"{s['name']}({s['change_pct']:+.2f}%)" for s in overview.bottom_concepts[:5]]) if overview.bottom_concepts else "æš‚æ— æ•°æ®"
        
        # é¾™è™æ¦œè‚¡ç¥¨
        lhb_text = ""
        for stock in overview.lhb_stocks[:5]:
            lhb_text += f"- {stock['name']}({stock['code']}): {stock['change_pct']:+.2f}%, å‡€ä¹°å…¥{stock['net_buy']:.2f}äº¿, {stock['reason']}\n"
        
        # æ–°é—»ä¿¡æ¯
        news_text = ""
        for i, n in enumerate(news[:6], 1):
            if hasattr(n, 'title'):
                title = n.title[:50] if n.title else ''
                snippet = n.snippet[:100] if n.snippet else ''
            else:
                title = n.get('title', '')[:50]
                snippet = n.get('snippet', '')[:100]
            news_text += f"{i}. {title}\n   {snippet}\n"
        
        # è®¡ç®—æ¶¨è·Œæ¯”
        total_stocks = overview.up_count + overview.down_count + overview.flat_count
        up_ratio = overview.up_count / total_stocks * 100 if total_stocks > 0 else 0
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„Aè‚¡å¸‚åœºåˆ†æå¸ˆï¼Œè¯·æ ¹æ®æä¾›çš„å¤šç»´åº¦æ•°æ®ç”Ÿæˆä¸€ä»½æ·±åº¦å¤§ç›˜å¤ç›˜æŠ¥å‘Šã€‚

ã€é‡è¦ã€‘è¾“å‡ºè¦æ±‚ï¼š
- å¿…é¡»è¾“å‡ºçº¯ Markdown æ–‡æœ¬æ ¼å¼
- ç¦æ­¢è¾“å‡º JSON æ ¼å¼å’Œä»£ç å—
- emoji ä»…åœ¨æ ‡é¢˜å¤„å°‘é‡ä½¿ç”¨

---

# ä»Šæ—¥å¸‚åœºæ•°æ®ï¼ˆ{overview.date}ï¼‰

## ä¸€ã€ä¸»è¦æŒ‡æ•°
{indices_text}

## äºŒã€å¸‚åœºæ¦‚å†µ
| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| ä¸Šæ¶¨å®¶æ•° | {overview.up_count} (æ¶¨è·Œæ¯” {up_ratio:.1f}%) |
| ä¸‹è·Œå®¶æ•° | {overview.down_count} |
| æ¶¨åœ | {overview.limit_up_count} |
| è·Œåœ | {overview.limit_down_count} |
| ä¸¤å¸‚æˆäº¤é¢ | {overview.total_amount:.0f}äº¿ |
| å¹³å‡æ¢æ‰‹ç‡ | {overview.avg_turnover_rate:.2f}% |
| é«˜æ¢æ‰‹(>10%)è‚¡ç¥¨æ•° | {overview.high_turnover_count} |

## ä¸‰ã€èµ„é‡‘æµå‘

### èèµ„èåˆ¸
- èèµ„ä½™é¢: {overview.margin_balance:.0f}äº¿
- èèµ„ä¹°å…¥é¢: {overview.margin_buy:.2f}äº¿
- èåˆ¸ä½™é¢: {overview.short_balance:.2f}äº¿

### å¤§å®—äº¤æ˜“
- æˆäº¤æ€»é¢: {overview.block_trade_amount:.2f}äº¿
- æº¢ä»·æˆäº¤å æ¯”: {overview.block_trade_premium_ratio:.1f}%
- æŠ˜ä»·æˆäº¤å æ¯”: {overview.block_trade_discount_ratio:.1f}%

## å››ã€æ¿å—è¡¨ç°

### è¡Œä¸šæ¿å—
- é¢†æ¶¨: {top_sectors_text}
- é¢†è·Œ: {bottom_sectors_text}

### æ¦‚å¿µæ¿å—
- çƒ­é—¨: {top_concepts_text}
- å†·é—¨: {bottom_concepts_text}

## äº”ã€é¾™è™æ¦œï¼ˆå‡€ä¹°å…¥: {overview.lhb_net_buy:.2f}äº¿ï¼‰
{lhb_text if lhb_text else "ä»Šæ—¥æ— é¾™è™æ¦œæ•°æ®"}

## å…­ã€å¸‚åœºæ–°é—»
{news_text if news_text else "æš‚æ— ç›¸å…³æ–°é—»"}

---

# åˆ†æè¦ç‚¹

è¯·é‡ç‚¹å…³æ³¨ï¼š
1. èèµ„ä½™é¢å˜åŒ–ï¼šæ æ†èµ„é‡‘æ˜¯åŠ ä»“è¿˜æ˜¯å‡ä»“ï¼Ÿ
2. å¤§å®—äº¤æ˜“æŠ˜æº¢ä»·ï¼šæŠ˜ä»·æˆäº¤å¤šè¯´æ˜å¤§è‚¡ä¸œ/æœºæ„åœ¨å‡ºè´§
3. é¾™è™æ¦œæœºæ„åŠ¨å‘ï¼šæœºæ„å¸­ä½ä¹°å…¥çš„æ¿å—å¾€å¾€æ˜¯ä¸­æœŸä¸»çº¿
4. æ¦‚å¿µæ¿å—è½®åŠ¨ï¼šå“ªäº›æ¦‚å¿µåœ¨æŒç»­å‘é…µï¼Ÿå“ªäº›åœ¨é€€æ½®ï¼Ÿ
5. æ¶¨è·Œæ¯”ä¸æˆäº¤é¢ï¼šèµšé’±æ•ˆåº”å¦‚ä½•ï¼Ÿé‡èƒ½æ˜¯å¦é…åˆï¼Ÿ

---

# è¾“å‡ºæ ¼å¼

## ğŸ“Š {overview.date} å¤§ç›˜å¤ç›˜

### ä¸€ã€å¸‚åœºæ€»ç»“
ï¼ˆæ¦‚æ‹¬ä»Šæ—¥å¸‚åœºè¡¨ç°ã€èµšé’±æ•ˆåº”ã€æˆäº¤é‡å˜åŒ–ï¼‰

### äºŒã€æŒ‡æ•°ç‚¹è¯„
ï¼ˆåˆ†æå„æŒ‡æ•°èµ°åŠ¿ç‰¹ç‚¹ï¼Œå¤§å°ç›˜é£æ ¼åˆ‡æ¢ï¼‰

### ä¸‰ã€èµ„é‡‘åŠ¨å‘è§£è¯»
ï¼ˆç»¼åˆåˆ†æèèµ„èåˆ¸ã€å¤§å®—äº¤æ˜“çš„ä¿¡å·å«ä¹‰ï¼‰

### å››ã€çƒ­ç‚¹è§£è¯»
ï¼ˆåˆ†ææ¿å—å’Œæ¦‚å¿µèƒŒåçš„é€»è¾‘ï¼Œåˆ¤æ–­æŒç»­æ€§ï¼‰

### äº”ã€é¾™è™æ¦œç‚¹è¯„
ï¼ˆåˆ†æä¸»åŠ›èµ„é‡‘åŠ¨å‘ï¼Œæœºæ„åå¥½çš„æ–¹å‘ï¼‰

### å…­ã€åå¸‚å±•æœ›
ï¼ˆç»™å‡ºæ˜æ—¥å¸‚åœºé¢„åˆ¤å’Œæ“ä½œå»ºè®®ï¼‰

### ä¸ƒã€é£é™©æç¤º
ï¼ˆéœ€è¦å…³æ³¨çš„é£é™©ç‚¹ï¼‰

---

è¯·ç›´æ¥è¾“å‡ºå¤ç›˜æŠ¥å‘Šå†…å®¹ã€‚
"""
        return prompt

    def _generate_template_review(self, overview: MarketOverview, news: List) -> str:
        """ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆå¤ç›˜æŠ¥å‘Šï¼ˆæ— å¤§æ¨¡å‹æ—¶çš„å¤‡é€‰æ–¹æ¡ˆï¼‰"""
        
        # åˆ¤æ–­å¸‚åœºèµ°åŠ¿
        sh_index = next((idx for idx in overview.indices if idx.code == '000001'), None)
        if sh_index:
            if sh_index.change_pct > 1:
                market_mood = "å¼ºåŠ¿ä¸Šæ¶¨"
            elif sh_index.change_pct > 0:
                market_mood = "å°å¹…ä¸Šæ¶¨"
            elif sh_index.change_pct > -1:
                market_mood = "å°å¹…ä¸‹è·Œ"
            else:
                market_mood = "æ˜æ˜¾ä¸‹è·Œ"
        else:
            market_mood = "éœ‡è¡æ•´ç†"
        
        # æŒ‡æ•°è¡Œæƒ…ï¼ˆç®€æ´æ ¼å¼ï¼‰
        indices_text = ""
        for idx in overview.indices[:4]:
            direction = "â†‘" if idx.change_pct > 0 else "â†“" if idx.change_pct < 0 else "-"
            indices_text += f"- **{idx.name}**: {idx.current:.2f} ({direction}{abs(idx.change_pct):.2f}%)\n"
        
        # æ¿å—ä¿¡æ¯
        top_text = "ã€".join([s['name'] for s in overview.top_sectors[:3]])
        bottom_text = "ã€".join([s['name'] for s in overview.bottom_sectors[:3]])
        
        report = f"""## ğŸ“Š {overview.date} å¤§ç›˜å¤ç›˜

### ä¸€ã€å¸‚åœºæ€»ç»“
ä»Šæ—¥Aè‚¡å¸‚åœºæ•´ä½“å‘ˆç°**{market_mood}**æ€åŠ¿ã€‚

### äºŒã€ä¸»è¦æŒ‡æ•°
{indices_text}

### ä¸‰ã€æ¶¨è·Œç»Ÿè®¡
| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| ä¸Šæ¶¨å®¶æ•° | {overview.up_count} |
| ä¸‹è·Œå®¶æ•° | {overview.down_count} |
| æ¶¨åœ | {overview.limit_up_count} |
| è·Œåœ | {overview.limit_down_count} |
| ä¸¤å¸‚æˆäº¤é¢ | {overview.total_amount:.0f}äº¿ |

### å››ã€æ¿å—è¡¨ç°
- **é¢†æ¶¨**: {top_text}
- **é¢†è·Œ**: {bottom_text}

### äº”ã€é£é™©æç¤º
å¸‚åœºæœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚ä»¥ä¸Šæ•°æ®ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚

---
*å¤ç›˜æ—¶é—´: {datetime.now().strftime('%H:%M')}*
"""
        return report
    
    def run_daily_review(self, target_date: Optional[str] = None, include_opportunity: bool = True) -> str:
        """
        æ‰§è¡Œæ¯æ—¥å¤§ç›˜å¤ç›˜æµç¨‹
        
        Args:
            target_date: ç›®æ ‡æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'ï¼Œé»˜è®¤ä¸ºä»Šå¤©
            include_opportunity: æ˜¯å¦åŒ…å«æ¿å—æœºä¼šåˆ†æ
        
        Returns:
            å¤ç›˜æŠ¥å‘Šæ–‡æœ¬
        """
        date_display = target_date or datetime.now().strftime('%Y-%m-%d')
        logger.info(f"========== å¼€å§‹å¤§ç›˜å¤ç›˜åˆ†æ ({date_display}) ==========")
        
        # 1. è·å–å¸‚åœºæ¦‚è§ˆ
        overview = self.get_market_overview(target_date)
        
        # 2. æœç´¢å¸‚åœºæ–°é—»ï¼ˆå†å²æ—¥æœŸæ—¶å¯èƒ½æœç´¢ä¸åˆ°ç›¸å…³æ–°é—»ï¼‰
        news = self.search_market_news()
        
        # 3. ç”Ÿæˆå¤ç›˜æŠ¥å‘Š
        report = self.generate_market_review(overview, news)
        
        # 4. æ·»åŠ æ¿å—æœºä¼šåˆ†æ
        if include_opportunity:
            try:
                opportunity_analyzer = SectorOpportunityAnalyzer(self.search_service, self.analyzer)
                opportunities = opportunity_analyzer.find_opportunity_sectors(fast_mode=True)
                opportunity_report = opportunity_analyzer.generate_opportunity_report(opportunities)
                report += "\n\n" + opportunity_report
            except Exception as e:
                logger.warning(f"[å¤§ç›˜] æ¿å—æœºä¼šåˆ†æå¤±è´¥: {e}")
        
        logger.info("========== å¤§ç›˜å¤ç›˜åˆ†æå®Œæˆ ==========")
        
        return report


# ============================================================
# æ¿å—åŸ‹ä¼æœºä¼šåˆ†ææ¨¡å—
# ============================================================

@dataclass
class SectorOpportunity:
    """
    æ¿å—åŸ‹ä¼æœºä¼š
    
    åŸ‹ä¼é€»è¾‘ï¼šå¿…é¡»åŒæ—¶æ»¡è¶³ä»¥ä¸‹ä¸‰ä¸ªæ¡ä»¶ä¸­çš„è‡³å°‘ä¸¤ä¸ªï¼Œèƒœç‡æ‰é«˜
    1. å¤Ÿä¾¿å®œï¼ˆå®‰å…¨å«ï¼‰ï¼šç»å†äº†é•¿æ—¶é—´è°ƒæ•´ï¼Œæœºæ„ä»“ä½ä½ï¼Œæ•£æˆ·ç»æœ›ï¼Œä¼°å€¼åœ¨å†å²åº•éƒ¨
    2. æœ‰å‚¬åŒ–ï¼ˆå¯¼ç«ç´¢ï¼‰ï¼šæœªæ¥3-6ä¸ªæœˆå†…æœ‰ç¡®å®šçš„æ”¿ç­–é¢„æœŸã€æŠ€æœ¯çªç ´æˆ–äº§å“è½åœ°
    3. æœ‰åè½¬ï¼ˆåŸºæœ¬é¢ï¼‰ï¼šè¡Œä¸šä¾›éœ€æ ¼å±€æ”¹å–„ï¼Œä»"æ€ä¼°å€¼"è½¬å‘"æ€ä¸šç»©"ç»“æŸï¼Œè¿›å…¥ä¸šç»©ä¿®å¤æœŸ
    """
    sector_name: str                    # æ¿å—åç§°
    sector_code: str                    # æ¿å—ä»£ç ï¼ˆç”³ä¸‡è¡Œä¸šä»£ç ï¼‰
    
    # ========== å¤Ÿä¾¿å®œï¼ˆå®‰å…¨å«ï¼‰==========
    current_pe: float = 0.0             # å½“å‰PE
    current_pb: float = 0.0             # å½“å‰PB
    pe_percentile: float = 100.0        # PEå†å²åˆ†ä½æ•° (0-100, è¶Šä½è¶Šä¾¿å®œ)
    pb_percentile: float = 100.0        # PBå†å²åˆ†ä½æ•°
    price_percentile: float = 100.0     # ä»·æ ¼å†å²åˆ†ä½æ•°ï¼ˆåŸºäº3å¹´æ•°æ®ï¼‰
    dividend_yield: float = 0.0         # è‚¡æ¯ç‡
    cheap_score: int = 0                # ä¾¿å®œå¾—åˆ† (0-4ï¼Œå¢åŠ ç­¹ç ç»´åº¦)
    cheap_reasons: List[str] = field(default_factory=list)  # ä¾¿å®œåŸå› 
    
    # ========== ç­¹ç é›†ä¸­åº¦ï¼ˆå®‰å…¨å«è¡¥å……ï¼‰==========
    avg_chip_concentration: float = 0.0  # æ¿å—å¹³å‡ç­¹ç é›†ä¸­åº¦ï¼ˆ90%é›†ä¸­åº¦ï¼‰
    avg_profit_ratio: float = 0.0        # æ¿å—å¹³å‡è·åˆ©æ¯”ä¾‹
    leader_chip_concentration: float = 0.0  # é¾™å¤´è‚¡ç­¹ç é›†ä¸­åº¦
    leader_profit_ratio: float = 0.0     # é¾™å¤´è‚¡è·åˆ©æ¯”ä¾‹
    leader_stock_name: str = ""          # é¾™å¤´è‚¡åç§°
    chip_analysis: str = ""              # ç­¹ç åˆ†æç»“è®º
    
    # ========== æœ‰å‚¬åŒ–ï¼ˆå¯¼ç«ç´¢ï¼‰==========
    recent_news: List[str] = field(default_factory=list)    # ç›¸å…³æ–°é—»æ ‡é¢˜
    policy_keywords: List[str] = field(default_factory=list)  # æ”¿ç­–å…³é”®è¯
    concept_heat: float = 0.0           # ç›¸å…³æ¦‚å¿µçƒ­åº¦
    catalyst_score: int = 0             # å‚¬åŒ–å¾—åˆ† (0-3)
    catalyst_reasons: List[str] = field(default_factory=list)  # å‚¬åŒ–åŸå› 
    
    # ========== æœ‰åè½¬ï¼ˆåŸºæœ¬é¢ï¼‰==========
    recent_5d_change: float = 0.0       # è¿‘5æ—¥æ¶¨è·Œå¹…
    recent_20d_change: float = 0.0      # è¿‘20æ—¥æ¶¨è·Œå¹…
    zt_count: int = 0                   # è¿‘æœŸæ¶¨åœè‚¡æ•°é‡
    lhb_net_buy: float = 0.0            # é¾™è™æ¦œå‡€ä¹°å…¥ï¼ˆäº¿å…ƒï¼‰
    volume_ratio: float = 0.0           # æˆäº¤é‡æ¯”ï¼ˆç›¸å¯¹20æ—¥å‡é‡ï¼‰
    reversal_score: int = 0             # åè½¬å¾—åˆ† (0-3)
    reversal_reasons: List[str] = field(default_factory=list)  # åè½¬åŸå› 
    
    # ========== ç»¼åˆè¯„ä¼° ==========
    total_score: int = 0                # æ€»åˆ† (0-10)
    recommendation: str = ""            # æ¨èç†ç”±
    risk_warning: str = ""              # é£é™©æç¤º
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'sector_name': self.sector_name,
            'sector_code': self.sector_code,
            'current_pe': self.current_pe,
            'current_pb': self.current_pb,
            'pe_percentile': self.pe_percentile,
            'price_percentile': self.price_percentile,
            'dividend_yield': self.dividend_yield,
            'cheap_score': self.cheap_score,
            'catalyst_score': self.catalyst_score,
            'reversal_score': self.reversal_score,
            'total_score': self.total_score,
            'recommendation': self.recommendation,
        }


class SectorOpportunityAnalyzer:
    """
    æ¿å—åŸ‹ä¼æœºä¼šåˆ†æå™¨
    
    æ ¸å¿ƒé€»è¾‘ï¼š
    1. å¤Ÿä¾¿å®œï¼šPE/PBå†å²åˆ†ä½æ•° < 30%ï¼Œæˆ–ä»·æ ¼å¤„äº3å¹´ä½ä½
    2. æœ‰å‚¬åŒ–ï¼šç›¸å…³æ¦‚å¿µè¿‘æœŸæ´»è·ƒï¼Œæˆ–æœ‰æ”¿ç­–/æŠ€æœ¯å‚¬åŒ–é¢„æœŸ
    3. æœ‰åè½¬ï¼šè¿‘æœŸæœ‰èµ„é‡‘æµå…¥è¿¹è±¡ï¼Œæ¶¨åœè‚¡å¢å¤šï¼Œé¾™è™æ¦œå‡€ä¹°å…¥
    
    æ”¯æŒ LLM æ·±åº¦åˆ†æï¼š
    - ä¼ å…¥ analyzer å‚æ•°åï¼Œå¯è°ƒç”¨ generate_ai_opportunity_report() ç”Ÿæˆ AI æ·±åº¦åˆ†ææŠ¥å‘Š
    - AI ä¼šç»¼åˆåˆ†ææ‰€æœ‰æ•°æ®ï¼Œç»™å‡ºæ›´ä¸“ä¸šçš„åŸ‹ä¼å»ºè®®
    """
    
    # ç”³ä¸‡ä¸€çº§è¡Œä¸šä»£ç æ˜ å°„ï¼ˆç”¨äºå†å²æ•°æ®æŸ¥è¯¢ï¼‰
    SW_INDUSTRY_CODES = {
        '801010.SI': 'å†œæ—ç‰§æ¸”',
        '801030.SI': 'åŸºç¡€åŒ–å·¥',
        '801040.SI': 'é’¢é“',
        '801050.SI': 'æœ‰è‰²é‡‘å±',
        '801080.SI': 'ç”µå­',
        '801110.SI': 'å®¶ç”¨ç”µå™¨',
        '801120.SI': 'é£Ÿå“é¥®æ–™',
        '801130.SI': 'çººç»‡æœé¥°',
        '801140.SI': 'è½»å·¥åˆ¶é€ ',
        '801150.SI': 'åŒ»è¯ç”Ÿç‰©',
        '801160.SI': 'å…¬ç”¨äº‹ä¸š',
        '801170.SI': 'äº¤é€šè¿è¾“',
        '801180.SI': 'æˆ¿åœ°äº§',
        '801200.SI': 'å•†è´¸é›¶å”®',
        '801210.SI': 'ç¤¾ä¼šæœåŠ¡',
        '801230.SI': 'ç»¼åˆ',
        '801710.SI': 'å»ºç­‘ææ–™',
        '801720.SI': 'å»ºç­‘è£…é¥°',
        '801730.SI': 'ç”µåŠ›è®¾å¤‡',
        '801740.SI': 'å›½é˜²å†›å·¥',
        '801750.SI': 'è®¡ç®—æœº',
        '801760.SI': 'ä¼ åª’',
        '801770.SI': 'é€šä¿¡',
        '801780.SI': 'é“¶è¡Œ',
        '801790.SI': 'éé“¶é‡‘è',
        '801880.SI': 'æ±½è½¦',
        '801890.SI': 'æœºæ¢°è®¾å¤‡',
        '801950.SI': 'ç…¤ç‚­',
        '801960.SI': 'çŸ³æ²¹çŸ³åŒ–',
        '801970.SI': 'ç¯ä¿',
        '801980.SI': 'ç¾å®¹æŠ¤ç†',
    }
    
    # æ”¿ç­–å‚¬åŒ–å…³é”®è¯ï¼ˆç”¨äºæ–°é—»åŒ¹é…ï¼‰
    POLICY_KEYWORDS = {
        'å†œæ—ç‰§æ¸”': ['ç²®é£Ÿå®‰å…¨', 'ä¹¡æ‘æŒ¯å…´', 'ç§ä¸š', 'å†œä¸šç°ä»£åŒ–'],
        'åŸºç¡€åŒ–å·¥': ['æ–°ææ–™', 'ç¢³ä¸­å’Œ', 'åŒ–å·¥æ–°ææ–™'],
        'é’¢é“': ['åŸºå»º', 'ç‰¹é’¢', 'é’¢é“é‡ç»„'],
        'æœ‰è‰²é‡‘å±': ['æ–°èƒ½æº', 'ç¨€åœŸ', 'é”‚ç”µ', 'é“œ'],
        'ç”µå­': ['åŠå¯¼ä½“', 'èŠ¯ç‰‡', 'å›½äº§æ›¿ä»£', 'AIèŠ¯ç‰‡'],
        'å®¶ç”¨ç”µå™¨': ['æ¶ˆè´¹å¤è‹', 'å®¶ç”µä¸‹ä¹¡', 'æ™ºèƒ½å®¶å±…'],
        'é£Ÿå“é¥®æ–™': ['æ¶ˆè´¹å‡çº§', 'ç™½é…’', 'é¢„åˆ¶èœ'],
        'åŒ»è¯ç”Ÿç‰©': ['åˆ›æ–°è¯', 'åŒ»ä¿', 'é›†é‡‡', 'ä¸­è¯'],
        'æˆ¿åœ°äº§': ['æˆ¿åœ°äº§æ”¿ç­–', 'ä¿äº¤æ¥¼', 'åŸä¸­æ‘'],
        'é“¶è¡Œ': ['é™æ¯', 'åˆ©ç‡', 'é‡‘èæ”¹é©'],
        'éé“¶é‡‘è': ['æ³¨å†Œåˆ¶', 'åˆ¸å•†', 'ä¿é™©'],
        'ç”µåŠ›è®¾å¤‡': ['æ–°èƒ½æº', 'å…‰ä¼', 'å‚¨èƒ½', 'ç”µç½‘'],
        'å›½é˜²å†›å·¥': ['å†›å·¥', 'å›½é˜²', 'èˆªç©ºèˆªå¤©'],
        'è®¡ç®—æœº': ['äººå·¥æ™ºèƒ½', 'AI', 'ä¿¡åˆ›', 'æ•°å­—ç»æµ'],
        'ä¼ åª’': ['æ¸¸æˆ', 'AIåº”ç”¨', 'çŸ­è§†é¢‘', 'æ–‡åŒ–'],
        'é€šä¿¡': ['5G', '6G', 'ç®—åŠ›', 'æ•°æ®ä¸­å¿ƒ'],
        'æ±½è½¦': ['æ–°èƒ½æºæ±½è½¦', 'æ™ºèƒ½é©¾é©¶', 'æ±½è½¦å‡ºæµ·'],
        'æœºæ¢°è®¾å¤‡': ['å·¥ä¸šæ¯æœº', 'æœºå™¨äºº', 'é«˜ç«¯è£…å¤‡'],
        'ç…¤ç‚­': ['èƒ½æºå®‰å…¨', 'ç…¤ç‚­ä¿ä¾›'],
        'çŸ³æ²¹çŸ³åŒ–': ['æ²¹ä»·', 'èƒ½æºå®‰å…¨', 'ç‚¼åŒ–'],
        'ç¯ä¿': ['ç¢³ä¸­å’Œ', 'ç¯ä¿ç£å¯Ÿ', 'åƒåœ¾å¤„ç†'],
        'ç¾å®¹æŠ¤ç†': ['å›½è´§ç¾å¦†', 'æ¶ˆè´¹å¤è‹'],
    }
    
    def __init__(self, search_service: Optional[SearchService] = None, analyzer=None):
        """
        åˆå§‹åŒ–æ¿å—æœºä¼šåˆ†æå™¨
        
        Args:
            search_service: æœç´¢æœåŠ¡å®ä¾‹ï¼ˆç”¨äºæœç´¢å‚¬åŒ–å‰‚æ–°é—»ï¼‰
            analyzer: AIåˆ†æå™¨å®ä¾‹ï¼ˆç”¨äºè°ƒç”¨LLMç”Ÿæˆæ·±åº¦åˆ†æï¼‰
        """
        self.search_service = search_service
        self.analyzer = analyzer
        self._sw_info_cache: Optional[pd.DataFrame] = None
        self._industry_hist_cache: Dict[str, pd.DataFrame] = {}
        self._em_industry_mapping: Optional[Dict[str, str]] = None  # ä¸œè´¢è¡Œä¸šæ¿å—åç§°->ä»£ç æ˜ å°„ç¼“å­˜
        
    def _call_akshare_with_retry(self, fn, name: str, attempts: int = 2):
        """å¸¦é‡è¯•çš„akshareè°ƒç”¨"""
        last_error: Optional[Exception] = None
        for attempt in range(1, attempts + 1):
            try:
                return fn()
            except Exception as e:
                last_error = e
                logger.warning(f"[æ¿å—æœºä¼š] {name} è·å–å¤±è´¥ (attempt {attempt}/{attempts}): {e}")
                if attempt < attempts:
                    time.sleep(min(2 ** attempt, 5))
        logger.error(f"[æ¿å—æœºä¼š] {name} æœ€ç»ˆå¤±è´¥: {last_error}")
        return None
    
    def _get_em_industry_mapping(self) -> Dict[str, str]:
        """
        è·å–ä¸œè´¢è¡Œä¸šæ¿å—åç§°åˆ°ä»£ç çš„æ˜ å°„
        
        Returns:
            {æ¿å—åç§°: æ¿å—ä»£ç } å­—å…¸ï¼Œå¦‚ {'å°é‡‘å±': 'BK1027', 'é“¶è¡Œ': 'BK0475'}
        """
        if not hasattr(self, '_em_industry_mapping') or self._em_industry_mapping is None:
            try:
                df = self._call_akshare_with_retry(ak.stock_board_industry_name_em, "ä¸œè´¢è¡Œä¸šæ¿å—åˆ—è¡¨")
                if df is not None and not df.empty:
                    # æ„å»ºåç§°åˆ°ä»£ç çš„æ˜ å°„
                    self._em_industry_mapping = {}
                    for _, row in df.iterrows():
                        name = str(row.get('æ¿å—åç§°', ''))
                        code = str(row.get('æ¿å—ä»£ç ', ''))
                        if name and code:
                            self._em_industry_mapping[name] = code
                    logger.info(f"[æ¿å—æœºä¼š] ç¼“å­˜ä¸œè´¢è¡Œä¸šæ¿å—æ˜ å°„: {len(self._em_industry_mapping)} ä¸ª")
                else:
                    self._em_industry_mapping = {}
            except Exception as e:
                logger.warning(f"[æ¿å—æœºä¼š] è·å–ä¸œè´¢è¡Œä¸šæ¿å—æ˜ å°„å¤±è´¥: {e}")
                self._em_industry_mapping = {}
        
        return self._em_industry_mapping
    
    def _find_em_sector(self, sector_name: str) -> Optional[str]:
        """
        æ ¹æ®ç”³ä¸‡è¡Œä¸šåç§°æŸ¥æ‰¾å¯¹åº”çš„ä¸œè´¢æ¿å—åç§°æˆ–ä»£ç 
        
        Args:
            sector_name: ç”³ä¸‡è¡Œä¸šåç§°ï¼ˆå¦‚"é“¶è¡Œ"ã€"æœ‰è‰²é‡‘å±"ï¼‰
            
        Returns:
            ä¸œè´¢æ¿å—åç§°æˆ–ä»£ç ï¼Œæ‰¾ä¸åˆ°è¿”å› None
        """
        mapping = self._get_em_industry_mapping()
        if not mapping:
            return None
        
        # 1. ç²¾ç¡®åŒ¹é…
        if sector_name in mapping:
            return sector_name
        
        # 2. æ¨¡ç³ŠåŒ¹é…ï¼ˆç”³ä¸‡åç§°å¯èƒ½ä¸ä¸œè´¢åç§°ç•¥æœ‰ä¸åŒï¼‰
        for em_name in mapping.keys():
            # åŒ…å«å…³ç³»åŒ¹é…
            if sector_name in em_name or em_name in sector_name:
                logger.debug(f"[æ¿å—æœºä¼š] æ¿å—åç§°åŒ¹é…: {sector_name} -> {em_name}")
                return em_name
            # å‰ä¸¤ä¸ªå­—åŒ¹é…
            if len(sector_name) >= 2 and len(em_name) >= 2 and sector_name[:2] == em_name[:2]:
                logger.debug(f"[æ¿å—æœºä¼š] æ¿å—åç§°å‰ç¼€åŒ¹é…: {sector_name} -> {em_name}")
                return em_name
        
        return None
    
    def _get_sector_constituents(self, sector_name: str, top_n: int = 5) -> List[Dict[str, Any]]:
        """
        è·å–æ¿å—æˆåˆ†è‚¡ï¼ˆæŒ‰å¸‚å€¼æ’åºå–å‰Nåªï¼‰
        
        ä¼˜åŒ–ç­–ç•¥ï¼š
        1. å…ˆä»ç¼“å­˜çš„ä¸œè´¢æ¿å—æ˜ å°„ä¸­æŸ¥æ‰¾æ­£ç¡®çš„æ¿å—åç§°
        2. ä½¿ç”¨æ­£ç¡®çš„æ¿å—åç§°æŸ¥è¯¢æˆåˆ†è‚¡
        3. æ”¯æŒä¼ å…¥æ¿å—ä»£ç ï¼ˆå¦‚ BK1027ï¼‰
        
        Args:
            sector_name: æ¿å—åç§°ï¼ˆç”³ä¸‡æˆ–ä¸œè´¢è¡Œä¸šæ¿å—åç§°ï¼‰
            top_n: è·å–å‰Nåªè‚¡ç¥¨
            
        Returns:
            æˆåˆ†è‚¡åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« code, name, market_cap
        """
        try:
            logger.debug(f"[æ¿å—æœºä¼š] è·å– {sector_name} æˆåˆ†è‚¡...")
            
            # æŸ¥æ‰¾æ­£ç¡®çš„ä¸œè´¢æ¿å—åç§°
            em_sector = self._find_em_sector(sector_name)
            query_name = em_sector if em_sector else sector_name
            
            # è·å–æˆåˆ†è‚¡
            df = self._call_akshare_with_retry(
                lambda: ak.stock_board_industry_cons_em(symbol=query_name),
                f"{query_name}æˆåˆ†è‚¡"
            )
            
            if df is None or df.empty:
                logger.warning(f"[æ¿å—æœºä¼š] {sector_name} æˆåˆ†è‚¡æ•°æ®ä¸ºç©º")
                return []
            
            # æŒ‰æ€»å¸‚å€¼æ’åºï¼ˆå¦‚æœæœ‰è¯¥åˆ—ï¼‰
            if 'æ€»å¸‚å€¼' in df.columns:
                df['æ€»å¸‚å€¼'] = pd.to_numeric(df['æ€»å¸‚å€¼'], errors='coerce')
                df = df.sort_values('æ€»å¸‚å€¼', ascending=False)
            
            # å–å‰Nåª
            result = []
            for _, row in df.head(top_n).iterrows():
                result.append({
                    'code': str(row.get('ä»£ç ', '')),
                    'name': str(row.get('åç§°', '')),
                    'market_cap': float(row.get('æ€»å¸‚å€¼', 0) or 0),
                })
            
            logger.debug(f"[æ¿å—æœºä¼š] {sector_name} è·å–åˆ° {len(result)} åªæˆåˆ†è‚¡")
            return result
            
        except Exception as e:
            logger.warning(f"[æ¿å—æœºä¼š] è·å– {sector_name} æˆåˆ†è‚¡å¤±è´¥: {e}")
            return []
    
    def _analyze_sector_chips(self, opp: SectorOpportunity, em_sector_name: Optional[str] = None) -> None:
        """
        åˆ†ææ¿å—ç­¹ç é›†ä¸­åº¦
        
        ç­–ç•¥ï¼š
        1. è·å–æ¿å—å‰3-5åªé¾™å¤´è‚¡ï¼ˆæŒ‰å¸‚å€¼ï¼‰
        2. è·å–æ¯åªè‚¡ç¥¨çš„ç­¹ç åˆ†å¸ƒæ•°æ®
        3. è®¡ç®—æ¿å—å¹³å‡ç­¹ç é›†ä¸­åº¦å’Œè·åˆ©æ¯”ä¾‹
        4. è¯†åˆ«é¾™å¤´è‚¡çš„ç­¹ç çŠ¶æ€
        
        Args:
            opp: æ¿å—æœºä¼šå¯¹è±¡
            em_sector_name: ä¸œè´¢æ¿å—åç§°ï¼ˆç”¨äºè·å–æˆåˆ†è‚¡ï¼‰
        """
        try:
            # ä½¿ç”¨ä¸œè´¢æ¿å—åç§°è·å–æˆåˆ†è‚¡
            sector_name = em_sector_name or opp.sector_name
            
            # è·å–æ¿å—é¾™å¤´è‚¡ï¼ˆå‰5åªï¼‰
            constituents = self._get_sector_constituents(sector_name, top_n=10)
            
            if not constituents:
                logger.debug(f"[æ¿å—æœºä¼š] {opp.sector_name} æ— æ³•è·å–æˆåˆ†è‚¡ï¼Œè·³è¿‡ç­¹ç åˆ†æ")
                return
            
            # å¯¼å…¥ AkshareFetcher è·å–ç­¹ç æ•°æ®
            from data_provider.akshare_fetcher import AkshareFetcher
            fetcher = AkshareFetcher(sleep_min=1, sleep_max=1.5)  # å‡å°‘ç­‰å¾…æ—¶é—´
            
            chip_data_list = []
            leader_chip = None
            leader_name = ""
            
            for i, stock in enumerate(constituents[:5]):  # åªåˆ†æå‰3åªï¼Œé¿å…APIè°ƒç”¨è¿‡å¤š
                code = stock['code']
                name = stock['name']
                
                try:
                    chip = fetcher.get_chip_distribution(code)
                    if chip:
                        chip_data_list.append({
                            'code': code,
                            'name': name,
                            'concentration_90': chip.concentration_90,
                            'profit_ratio': chip.profit_ratio,
                            'avg_cost': chip.avg_cost,
                        })
                        
                        # ç¬¬ä¸€åªå°±æ˜¯é¾™å¤´è‚¡
                        if i == 0:
                            leader_chip = chip
                            leader_name = name
                            
                except Exception as e:
                    logger.debug(f"[æ¿å—æœºä¼š] è·å– {code} ç­¹ç æ•°æ®å¤±è´¥: {e}")
                    continue
                
                time.sleep(0.3)  # é¿å…è¯·æ±‚è¿‡å¿«
            
            if not chip_data_list:
                logger.debug(f"[æ¿å—æœºä¼š] {opp.sector_name} æ— æœ‰æ•ˆç­¹ç æ•°æ®")
                return
            
            # è®¡ç®—æ¿å—å¹³å‡å€¼
            avg_concentration = sum(d['concentration_90'] for d in chip_data_list) / len(chip_data_list)
            avg_profit = sum(d['profit_ratio'] for d in chip_data_list) / len(chip_data_list)
            
            # æ›´æ–°æ¿å—æœºä¼šå¯¹è±¡
            opp.avg_chip_concentration = avg_concentration
            opp.avg_profit_ratio = avg_profit
            
            if leader_chip:
                opp.leader_chip_concentration = leader_chip.concentration_90
                opp.leader_profit_ratio = leader_chip.profit_ratio
                opp.leader_stock_name = leader_name
            
            # ç”Ÿæˆç­¹ç åˆ†æç»“è®º
            analysis_parts = []
            
            # ç­¹ç é›†ä¸­åº¦åˆ†æ
            if avg_concentration < 0.10:
                analysis_parts.append("ç­¹ç é«˜åº¦é›†ä¸­")
            elif avg_concentration < 0.15:
                analysis_parts.append("ç­¹ç è¾ƒé›†ä¸­")
            elif avg_concentration < 0.25:
                analysis_parts.append("ç­¹ç åˆ†æ•£åº¦ä¸­ç­‰")
            else:
                analysis_parts.append("ç­¹ç è¾ƒåˆ†æ•£")
            
            # è·åˆ©æ¯”ä¾‹åˆ†æ
            if avg_profit < 0.30:
                analysis_parts.append("å¥—ç‰¢ç›˜è¾ƒé‡(è·åˆ©<30%)")
            elif avg_profit < 0.50:
                analysis_parts.append("è·åˆ©ç›˜ä¸­ç­‰(30-50%)")
            elif avg_profit < 0.70:
                analysis_parts.append("è·åˆ©ç›˜è¾ƒå¤š(50-70%)")
            else:
                analysis_parts.append("è·åˆ©ç›˜æé«˜(>70%)")
            
            opp.chip_analysis = "ï¼Œ".join(analysis_parts)
            
            logger.info(f"[æ¿å—æœºä¼š] {opp.sector_name} ç­¹ç åˆ†æ: å¹³å‡é›†ä¸­åº¦={avg_concentration:.1%}, "
                       f"å¹³å‡è·åˆ©æ¯”ä¾‹={avg_profit:.1%}, é¾™å¤´={leader_name}")
            
        except Exception as e:
            logger.warning(f"[æ¿å—æœºä¼š] {opp.sector_name} ç­¹ç åˆ†æå¤±è´¥: {e}")
    
    def _get_sw_industry_info(self) -> Optional[pd.DataFrame]:
        """è·å–ç”³ä¸‡ä¸€çº§è¡Œä¸šå½“å‰ä¼°å€¼ä¿¡æ¯"""
        if self._sw_info_cache is not None:
            return self._sw_info_cache
        
        try:
            logger.info("[æ¿å—æœºä¼š] è·å–ç”³ä¸‡è¡Œä¸šä¼°å€¼ä¿¡æ¯...")
            df = self._call_akshare_with_retry(ak.sw_index_first_info, "ç”³ä¸‡è¡Œä¸šä¿¡æ¯")
            if df is not None:
                self._sw_info_cache = df
                logger.info(f"[æ¿å—æœºä¼š] è·å–åˆ° {len(df)} ä¸ªç”³ä¸‡ä¸€çº§è¡Œä¸š")
            return df
        except Exception as e:
            logger.error(f"[æ¿å—æœºä¼š] è·å–ç”³ä¸‡è¡Œä¸šä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def _get_industry_hist(self, symbol: str, days: int = 750) -> Optional[pd.DataFrame]:
        """
        è·å–ç”³ä¸‡è¡Œä¸šæŒ‡æ•°å†å²æ•°æ®ï¼ˆçº¦3å¹´ï¼‰
        
        Args:
            symbol: ç”³ä¸‡è¡Œä¸šä»£ç ï¼Œå¦‚ '801030'
            days: è·å–å¤©æ•°
        """
        if symbol in self._industry_hist_cache:
            return self._industry_hist_cache[symbol]
        
        try:
            df = self._call_akshare_with_retry(
                lambda: ak.index_hist_sw(symbol=symbol, period='day'),
                f"ç”³ä¸‡æŒ‡æ•°å†å²({symbol})"
            )
            if df is not None and not df.empty:
                # åªä¿ç•™æœ€è¿‘Nå¤©
                df = df.tail(days).copy()
                self._industry_hist_cache[symbol] = df
            return df
        except Exception as e:
            logger.warning(f"[æ¿å—æœºä¼š] è·å– {symbol} å†å²æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _calculate_price_percentile(self, symbol: str) -> float:
        """
        è®¡ç®—ä»·æ ¼å†å²åˆ†ä½æ•°
        
        Args:
            symbol: ç”³ä¸‡è¡Œä¸šä»£ç 
            
        Returns:
            åˆ†ä½æ•° (0-100)ï¼Œè¶Šä½è¡¨ç¤ºå½“å‰ä»·æ ¼è¶Šä¾¿å®œ
        """
        # ä¸ºäº†æé«˜æ•ˆç‡ï¼Œä½¿ç”¨ç®€åŒ–çš„ä¼°ç®—æ–¹æ³•
        # åŸºäºå½“å‰PE/PBä¸å†å²å‡å€¼çš„æ¯”è¾ƒ
        return 50.0  # é»˜è®¤ä¸­ä½æ•°ï¼Œåç»­å¯é€šè¿‡æ‰¹é‡è·å–ä¼˜åŒ–
    
    def _calculate_price_percentile_batch(self, symbols: List[str]) -> Dict[str, float]:
        """
        æ‰¹é‡è®¡ç®—ä»·æ ¼å†å²åˆ†ä½æ•°ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        Args:
            symbols: ç”³ä¸‡è¡Œä¸šä»£ç åˆ—è¡¨
            
        Returns:
            {symbol: percentile} å­—å…¸
        """
        result = {}
        for symbol in symbols:
            df = self._get_industry_hist(symbol)
            if df is None or df.empty:
                result[symbol] = 50.0
                continue
            
            try:
                current_price = float(df['æ”¶ç›˜'].iloc[-1])
                all_prices = df['æ”¶ç›˜'].astype(float)
                percentile = (all_prices < current_price).sum() / len(all_prices) * 100
                result[symbol] = percentile
            except Exception as e:
                logger.warning(f"[æ¿å—æœºä¼š] è®¡ç®— {symbol} ä»·æ ¼åˆ†ä½æ•°å¤±è´¥: {e}")
                result[symbol] = 50.0
        
        return result
    
    def _get_em_industry_realtime(self) -> Optional[pd.DataFrame]:
        """è·å–ä¸œè´¢è¡Œä¸šæ¿å—å®æ—¶è¡Œæƒ…"""
        try:
            df = self._call_akshare_with_retry(ak.stock_board_industry_name_em, "ä¸œè´¢è¡Œä¸šæ¿å—")
            return df
        except Exception as e:
            logger.error(f"[æ¿å—æœºä¼š] è·å–ä¸œè´¢è¡Œä¸šæ¿å—å¤±è´¥: {e}")
            return None
    
    def _get_zt_pool_by_industry(self, date: Optional[str] = None) -> Dict[str, int]:
        """
        è·å–å„è¡Œä¸šæ¶¨åœè‚¡æ•°é‡
        
        Returns:
            {è¡Œä¸šåç§°: æ¶¨åœæ•°é‡}
        """
        if date is None:
            date = datetime.now().strftime('%Y%m%d')
        
        industry_zt_count: Dict[str, int] = {}
        
        try:
            df = self._call_akshare_with_retry(
                lambda: ak.stock_zt_pool_em(date=date),
                "æ¶¨åœè‚¡æ± "
            )
            if df is not None and not df.empty and 'æ‰€å±è¡Œä¸š' in df.columns:
                industry_zt_count = df['æ‰€å±è¡Œä¸š'].value_counts().to_dict()
                logger.info(f"[æ¿å—æœºä¼š] æ¶¨åœè‚¡æ± : {len(df)} åªï¼Œæ¶‰åŠ {len(industry_zt_count)} ä¸ªè¡Œä¸š")
        except Exception as e:
            logger.warning(f"[æ¿å—æœºä¼š] è·å–æ¶¨åœè‚¡æ± å¤±è´¥: {e}")
        
        return industry_zt_count
    
    def _get_fund_position(self) -> float:
        """è·å–å½“å‰è‚¡ç¥¨å‹åŸºé‡‘ä»“ä½"""
        try:
            df = self._call_akshare_with_retry(ak.fund_stock_position_lg, "åŸºé‡‘ä»“ä½")
            if df is not None and not df.empty:
                return float(df['position'].iloc[-1])
        except Exception as e:
            logger.warning(f"[æ¿å—æœºä¼š] è·å–åŸºé‡‘ä»“ä½å¤±è´¥: {e}")
        return 90.0  # é»˜è®¤å€¼
    
    def _analyze_cheap(self, opp: SectorOpportunity, sw_row: pd.Series, 
                       price_percentiles: Optional[Dict[str, float]] = None) -> None:
        """
        åˆ†æ"å¤Ÿä¾¿å®œ"ç»´åº¦
        
        è¯„åˆ†æ ‡å‡†ï¼š
        - PEåˆ†ä½æ•° < 20%: +1åˆ†
        - PBåˆ†ä½æ•° < 20%: +1åˆ†  
        - ä»·æ ¼åˆ†ä½æ•° < 30%: +1åˆ†
        - è‚¡æ¯ç‡ > 3%: +1åˆ†ï¼ˆé¢å¤–åŠ åˆ†ï¼‰
        - ç­¹ç é›†ä¸­åº¦ä½ + è·åˆ©æ¯”ä¾‹ä½: +1åˆ†ï¼ˆç­¹ç ç»´åº¦ï¼‰
        """
        score = 0
        reasons = []
        
        # è·å–å½“å‰ä¼°å€¼
        opp.current_pe = float(sw_row.get('TTM(æ»šåŠ¨)å¸‚ç›ˆç‡', 0) or 0)
        opp.current_pb = float(sw_row.get('å¸‚å‡€ç‡', 0) or 0)
        opp.dividend_yield = float(sw_row.get('é™æ€è‚¡æ¯ç‡', 0) or 0)
        
        # è·å–ä»·æ ¼åˆ†ä½æ•°
        code = str(sw_row.get('è¡Œä¸šä»£ç ', '')).replace('.SI', '')
        if price_percentiles and code in price_percentiles:
            opp.price_percentile = price_percentiles[code]
        else:
            opp.price_percentile = 50.0  # é»˜è®¤å€¼
        
        # ç®€åŒ–çš„PE/PBåˆ†ä½æ•°ä¼°ç®—ï¼ˆåŸºäºä»·æ ¼åˆ†ä½æ•°ï¼‰
        opp.pe_percentile = opp.price_percentile
        opp.pb_percentile = opp.price_percentile
        
        # è¯„åˆ†
        if opp.price_percentile < 20:
            score += 1
            reasons.append(f"ä»·æ ¼å¤„äºå†å²{opp.price_percentile:.0f}%åˆ†ä½ï¼ˆæä½ï¼‰")
        elif opp.price_percentile < 30:
            score += 1
            reasons.append(f"ä»·æ ¼å¤„äºå†å²{opp.price_percentile:.0f}%åˆ†ä½ï¼ˆè¾ƒä½ï¼‰")
        
        # PEè¯„ä¼°ï¼ˆä½PEè¡Œä¸šæ›´ä¾¿å®œï¼‰
        if opp.current_pe > 0 and opp.current_pe < 15:
            score += 1
            reasons.append(f"PEä»…{opp.current_pe:.1f}å€ï¼ˆä½ä¼°å€¼ï¼‰")
        
        # é«˜è‚¡æ¯
        if opp.dividend_yield > 3:
            score += 1
            reasons.append(f"è‚¡æ¯ç‡{opp.dividend_yield:.2f}%ï¼ˆé«˜åˆ†çº¢ï¼‰")
        
        # ç­¹ç ç»´åº¦è¯„åˆ†ï¼ˆå¦‚æœæœ‰ç­¹ç æ•°æ®ï¼‰
        if opp.avg_chip_concentration > 0:
            # ç­¹ç é›†ä¸­åº¦ä½ï¼ˆ<15%ï¼‰ä¸”è·åˆ©æ¯”ä¾‹ä½ï¼ˆ<40%ï¼‰è¡¨ç¤ºå–å‹å·²é‡Šæ”¾
            if opp.avg_chip_concentration < 0.15 and opp.avg_profit_ratio < 0.40:
                score += 1
                reasons.append(f"ç­¹ç é›†ä¸­({opp.avg_chip_concentration:.0%})ä¸”å¥—ç‰¢ç›˜é‡({opp.avg_profit_ratio:.0%})ï¼Œå–å‹é‡Šæ”¾")
            elif opp.avg_chip_concentration < 0.12:
                score += 1
                reasons.append(f"ç­¹ç é«˜åº¦é›†ä¸­({opp.avg_chip_concentration:.0%})ï¼Œä¸»åŠ›æ§ç›˜")
            elif opp.avg_profit_ratio < 0.30:
                score += 1
                reasons.append(f"è·åˆ©ç›˜æä½({opp.avg_profit_ratio:.0%})ï¼ŒæŠ›å‹æ¯ç«­")
        
        opp.cheap_score = min(score, 4)  # æœ€é«˜4åˆ†ï¼ˆå¢åŠ ç­¹ç ç»´åº¦ï¼‰
        opp.cheap_reasons = reasons
    
    def _analyze_catalyst(self, opp: SectorOpportunity, concept_df: Optional[pd.DataFrame] = None,
                          search_result: Optional[Dict[str, Any]] = None) -> None:
        """
        åˆ†æ"æœ‰å‚¬åŒ–"ç»´åº¦
        
        è¯„åˆ†æ ‡å‡†ï¼š
        - ç›¸å…³æ¦‚å¿µè¿‘5æ—¥æ¶¨å¹… > 5%: +1åˆ†
        - æœ‰æ”¿ç­–å…³é”®è¯åŒ¹é…: +1åˆ†
        - è¿‘æœŸæœ‰ç›¸å…³æ–°é—»/æ”¿ç­–: +1åˆ†ï¼ˆé€šè¿‡æ™ºèƒ½æœç´¢è·å–ï¼‰
        
        Args:
            opp: æ¿å—æœºä¼šå¯¹è±¡
            concept_df: æ¦‚å¿µæ¿å—æ•°æ®
            search_result: æ™ºèƒ½æœç´¢ç»“æœï¼ˆå¯é€‰ï¼‰
        """
        score = 0
        reasons = []
        
        # è·å–ç›¸å…³æ”¿ç­–å…³é”®è¯
        keywords = self.POLICY_KEYWORDS.get(opp.sector_name, [])
        opp.policy_keywords = keywords
        
        # æ£€æŸ¥æ¦‚å¿µæ¿å—çƒ­åº¦ï¼ˆä½¿ç”¨ä¼ å…¥çš„ç¼“å­˜æ•°æ®ï¼‰
        if concept_df is not None and not concept_df.empty:
            try:
                # æŸ¥æ‰¾ä¸è¡Œä¸šç›¸å…³çš„æ¦‚å¿µ
                for keyword in keywords:
                    matched = concept_df[concept_df['æ¿å—åç§°'].str.contains(keyword, na=False)]
                    if not matched.empty:
                        change = float(matched['æ¶¨è·Œå¹…'].iloc[0])
                        if change > 3:
                            score += 1
                            reasons.append(f"ç›¸å…³æ¦‚å¿µ'{keyword}'ä»Šæ—¥æ¶¨{change:.1f}%")
                            opp.concept_heat = change
                            break
            except Exception as e:
                logger.warning(f"[æ¿å—æœºä¼š] æ£€æŸ¥æ¦‚å¿µçƒ­åº¦å¤±è´¥: {e}")
        
        # ä½¿ç”¨æ™ºèƒ½æœç´¢ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
        if search_result and search_result.get('success'):
            catalyst_results = search_result.get('catalyst', {})
            if catalyst_results.get('results'):
                score += 1
                # æå–æœç´¢åˆ°çš„å‚¬åŒ–å‰‚ä¿¡æ¯
                top_news = catalyst_results['results'][:2]
                news_titles = [r.title[:30] for r in top_news]
                reasons.append(f"æœç´¢åˆ°å‚¬åŒ–å‰‚: {'; '.join(news_titles)}")
                opp.recent_news = [r.title for r in catalyst_results['results'][:5]]
            
            # å¦‚æœæœ‰ LLM æ‘˜è¦ï¼Œæ·»åŠ åˆ°åŸå› ä¸­
            if catalyst_results.get('summary'):
                reasons.append(f"AIåˆ†æ: {catalyst_results['summary'][:100]}")
        
        # æ”¿ç­–å…³é”®è¯æœ¬èº«å°±æ˜¯å‚¬åŒ–ä¿¡å·
        if keywords and score == 0:
            score += 1
            reasons.append(f"å…³æ³¨å‚¬åŒ–: {', '.join(keywords[:3])}")
        
        opp.catalyst_score = min(score, 3)
        opp.catalyst_reasons = reasons
    
    def _analyze_reversal(self, opp: SectorOpportunity, em_row: Optional[pd.Series], 
                          zt_count_map: Dict[str, int]) -> None:
        """
        åˆ†æ"æœ‰åè½¬"ç»´åº¦
        
        è¯„åˆ†æ ‡å‡†ï¼š
        - è¿‘5æ—¥æ¶¨å¹… > 3%: +1åˆ†ï¼ˆèµ„é‡‘å¼€å§‹å…³æ³¨ï¼‰
        - è¡Œä¸šæ¶¨åœè‚¡ >= 3åª: +1åˆ†ï¼ˆèµšé’±æ•ˆåº”ï¼‰
        - æ¢æ‰‹ç‡æ”¾å¤§: +1åˆ†ï¼ˆé‡èƒ½é…åˆï¼‰
        """
        score = 0
        reasons = []
        
        # ä»ä¸œè´¢æ•°æ®è·å–è¿‘æœŸè¡¨ç°
        if em_row is not None:
            try:
                opp.recent_5d_change = float(em_row.get('æ¶¨è·Œå¹…', 0) or 0)
                
                # è¿‘æœŸæ¶¨å¹…åˆ¤æ–­
                if opp.recent_5d_change > 5:
                    score += 1
                    reasons.append(f"ä»Šæ—¥æ¶¨{opp.recent_5d_change:.1f}%ï¼ˆå¼ºåŠ¿ï¼‰")
                elif opp.recent_5d_change > 2:
                    score += 1
                    reasons.append(f"ä»Šæ—¥æ¶¨{opp.recent_5d_change:.1f}%ï¼ˆèµ°å¼ºï¼‰")
                
                # æ¢æ‰‹ç‡
                turnover = float(em_row.get('æ¢æ‰‹ç‡', 0) or 0)
                if turnover > 2:
                    score += 1
                    reasons.append(f"æ¢æ‰‹ç‡{turnover:.1f}%ï¼ˆæ´»è·ƒï¼‰")
                    opp.volume_ratio = turnover
            except Exception as e:
                logger.warning(f"[æ¿å—æœºä¼š] è§£æä¸œè´¢æ•°æ®å¤±è´¥: {e}")
        
        # æ¶¨åœè‚¡æ•°é‡
        # éœ€è¦åŒ¹é…è¡Œä¸šåç§°ï¼ˆä¸œè´¢å’Œç”³ä¸‡å‘½åå¯èƒ½ä¸åŒï¼‰
        for industry_name, count in zt_count_map.items():
            if opp.sector_name in industry_name or industry_name in opp.sector_name:
                opp.zt_count = count
                if count >= 5:
                    score += 1
                    reasons.append(f"æ¶¨åœ{count}åªï¼ˆèµšé’±æ•ˆåº”å¼ºï¼‰")
                elif count >= 3:
                    score += 1
                    reasons.append(f"æ¶¨åœ{count}åªï¼ˆæœ‰èµšé’±æ•ˆåº”ï¼‰")
                break
        
        opp.reversal_score = min(score, 3)
        opp.reversal_reasons = reasons
    
    def _generate_recommendation(self, opp: SectorOpportunity) -> None:
        """ç”Ÿæˆæ¨èç†ç”±å’Œé£é™©æç¤º"""
        opp.total_score = opp.cheap_score + opp.catalyst_score + opp.reversal_score
        
        # ç»Ÿè®¡æ»¡è¶³æ¡ä»¶æ•°ï¼ˆä¾¿å®œç»´åº¦é˜ˆå€¼è°ƒæ•´ä¸º>=2ï¼Œå› ä¸ºæœ€é«˜4åˆ†ï¼‰
        conditions_met = sum([
            opp.cheap_score >= 2,
            opp.catalyst_score >= 1,
            opp.reversal_score >= 1
        ])
        
        # ç”Ÿæˆæ¨èç†ç”±
        all_reasons = opp.cheap_reasons + opp.catalyst_reasons + opp.reversal_reasons
        
        # æ·»åŠ ç­¹ç åˆ†æç»“è®º
        if opp.chip_analysis:
            all_reasons.append(f"ç­¹ç : {opp.chip_analysis}")
        
        if conditions_met >= 2:
            opp.recommendation = f"ã€æ¨èåŸ‹ä¼ã€‘æ»¡è¶³{conditions_met}/3æ¡ä»¶ã€‚" + "ï¼›".join(all_reasons[:4])
        elif conditions_met == 1:
            opp.recommendation = f"ã€è§‚å¯Ÿã€‘ä»…æ»¡è¶³1ä¸ªæ¡ä»¶ã€‚" + "ï¼›".join(all_reasons[:3])
        else:
            opp.recommendation = f"ã€æš‚ä¸æ¨èã€‘æ¡ä»¶ä¸è¶³ã€‚"
        
        # é£é™©æç¤º
        risks = []
        if opp.cheap_score == 0:
            risks.append("ä¼°å€¼ä¸ä¾¿å®œ")
        if opp.catalyst_score == 0:
            risks.append("ç¼ºä¹å‚¬åŒ–å‰‚")
        if opp.reversal_score == 0:
            risks.append("å°šæ— åè½¬ä¿¡å·")
        # ç­¹ç é£é™©æç¤º
        if opp.avg_profit_ratio > 0.80:
            risks.append("è·åˆ©ç›˜è¿‡é«˜ï¼Œæ³¨æ„æŠ›å‹")
        opp.risk_warning = "ï¼›".join(risks) if risks else "æš‚æ— æ˜æ˜¾é£é™©"
    
    def find_opportunity_sectors(self, fast_mode: bool = True, use_smart_search: bool = True, 
                                   analyze_chips: bool = True) -> List[SectorOpportunity]:
        """
        å¯»æ‰¾ç¬¦åˆåŸ‹ä¼æ¡ä»¶çš„æ¿å—
        
        Args:
            fast_mode: å¿«é€Ÿæ¨¡å¼ï¼Œè·³è¿‡è€—æ—¶çš„å†å²æ•°æ®è®¡ç®—
            use_smart_search: æ˜¯å¦ä½¿ç”¨æ™ºèƒ½æœç´¢è·å–å‚¬åŒ–å‰‚ä¿¡æ¯
            analyze_chips: æ˜¯å¦åˆ†æç­¹ç é›†ä¸­åº¦ï¼ˆä¼šå¢åŠ APIè°ƒç”¨ï¼‰
        
        Returns:
            æŒ‰æ€»åˆ†æ’åºçš„æ¿å—æœºä¼šåˆ—è¡¨
        """
        logger.info("========== å¼€å§‹æ¿å—æœºä¼šåˆ†æ ==========")
        
        opportunities: List[SectorOpportunity] = []
        
        # 1. è·å–ç”³ä¸‡è¡Œä¸šä¼°å€¼æ•°æ®
        sw_df = self._get_sw_industry_info()
        if sw_df is None or sw_df.empty:
            logger.error("[æ¿å—æœºä¼š] æ— æ³•è·å–ç”³ä¸‡è¡Œä¸šæ•°æ®")
            return opportunities
        
        # 2. è·å–ä¸œè´¢è¡Œä¸šæ¿å—å®æ—¶æ•°æ®
        em_df = self._get_em_industry_realtime()
        
        # 3. è·å–æ¶¨åœè‚¡æ± æŒ‰è¡Œä¸šç»Ÿè®¡
        zt_count_map = self._get_zt_pool_by_industry()
        
        # 4. è·å–æ¦‚å¿µæ¿å—æ•°æ®ï¼ˆä¸€æ¬¡æ€§è·å–ï¼Œé¿å…é‡å¤è°ƒç”¨ï¼‰
        concept_df = self._call_akshare_with_retry(ak.stock_board_concept_name_em, "æ¦‚å¿µæ¿å—")
        
        # 5. æ‰¹é‡è®¡ç®—ä»·æ ¼åˆ†ä½æ•°ï¼ˆå¦‚æœä¸æ˜¯å¿«é€Ÿæ¨¡å¼ï¼‰
        price_percentiles: Optional[Dict[str, float]] = None
        if not fast_mode:
            logger.info("[æ¿å—æœºä¼š] è®¡ç®—å†å²ä»·æ ¼åˆ†ä½æ•°ï¼ˆè€—æ—¶è¾ƒé•¿ï¼‰...")
            symbols = [str(row['è¡Œä¸šä»£ç ']).replace('.SI', '') for _, row in sw_df.iterrows()]
            price_percentiles = self._calculate_price_percentile_batch(symbols)
        
        # 6. åˆå§‹åŒ–æ™ºèƒ½æœç´¢æœåŠ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        smart_search = None
        sector_search_results: Dict[str, Dict[str, Any]] = {}
        
        if use_smart_search and self.search_service and self.analyzer:
            try:
                from search_service import SmartSearchService
                # åˆ›å»ºæ™ºèƒ½æœç´¢æœåŠ¡
                smart_search = SmartSearchService(
                    bocha_keys=getattr(self.search_service, '_providers', []),
                    analyzer=self.analyzer
                )
                # å¤ç”¨ç°æœ‰çš„æœç´¢å¼•æ“
                smart_search._providers = self.search_service._providers
                logger.info("[æ¿å—æœºä¼š] å·²å¯ç”¨æ™ºèƒ½æœç´¢æœåŠ¡")
            except Exception as e:
                logger.warning(f"[æ¿å—æœºä¼š] åˆå§‹åŒ–æ™ºèƒ½æœç´¢å¤±è´¥: {e}")
        
        # 7. å¯¹é«˜æ½œåŠ›æ¿å—è¿›è¡Œæ™ºèƒ½æœç´¢ï¼ˆåªæœç´¢ä¼°å€¼è¾ƒä½çš„å‰10ä¸ªæ¿å—ï¼‰
        if smart_search and smart_search.is_available:
            # å…ˆå¿«é€Ÿç­›é€‰å‡ºå¯èƒ½æœ‰ä»·å€¼çš„æ¿å—
            potential_sectors = []
            for _, sw_row in sw_df.iterrows():
                sector_name = str(sw_row.get('è¡Œä¸šåç§°', ''))
                pe = float(sw_row.get('TTM(æ»šåŠ¨)å¸‚ç›ˆç‡', 100) or 100)
                dividend = float(sw_row.get('é™æ€è‚¡æ¯ç‡', 0) or 0)
                # ä½PEæˆ–é«˜è‚¡æ¯çš„æ¿å—ä¼˜å…ˆæœç´¢
                if pe < 20 or dividend > 3:
                    potential_sectors.append(sector_name)
            
            # é™åˆ¶æœç´¢æ•°é‡ï¼ˆé¿å…APIè°ƒç”¨è¿‡å¤šï¼‰
            sectors_to_search = potential_sectors[:5]
            
            if sectors_to_search:
                logger.info(f"[æ¿å—æœºä¼š] å¯¹ {len(sectors_to_search)} ä¸ªé«˜æ½œåŠ›æ¿å—è¿›è¡Œæ™ºèƒ½æœç´¢...")
                
                for sector_name in sectors_to_search:
                    try:
                        keywords = self.POLICY_KEYWORDS.get(sector_name, [])
                        result = smart_search.search_sector_comprehensive(
                            sector_name, 
                            policy_keywords=keywords,
                            use_llm=True
                        )
                        sector_search_results[sector_name] = result
                        logger.info(f"[æ¿å—æœºä¼š] {sector_name} æ™ºèƒ½æœç´¢å®Œæˆ")
                        time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
                    except Exception as e:
                        logger.warning(f"[æ¿å—æœºä¼š] {sector_name} æ™ºèƒ½æœç´¢å¤±è´¥: {e}")
        
        # 8. éå†æ¯ä¸ªè¡Œä¸šè¿›è¡Œåˆ†æ
        for _, sw_row in sw_df.iterrows():
            sector_name = str(sw_row.get('è¡Œä¸šåç§°', ''))
            sector_code = str(sw_row.get('è¡Œä¸šä»£ç ', ''))
            
            if not sector_name:
                continue
            
            opp = SectorOpportunity(
                sector_name=sector_name,
                sector_code=sector_code
            )
            
            # åŒ¹é…ä¸œè´¢æ•°æ®ï¼ˆæå‰åŒ¹é…ï¼Œç”¨äºç­¹ç åˆ†æï¼‰
            em_row = None
            em_sector_name = None
            if em_df is not None and not em_df.empty:
                matched = em_df[em_df['æ¿å—åç§°'].str.contains(sector_name[:2], na=False)]
                if not matched.empty:
                    em_row = matched.iloc[0]
                    em_sector_name = str(em_row.get('æ¿å—åç§°', ''))
            
            # åˆ†æç­¹ç é›†ä¸­åº¦ï¼ˆåœ¨ _analyze_cheap ä¹‹å‰ï¼Œå› ä¸ºç­¹ç æ•°æ®ä¼šå½±å“ä¾¿å®œå¾—åˆ†ï¼‰
            if analyze_chips:
                # åªå¯¹ä½ä¼°å€¼æ¿å—è¿›è¡Œç­¹ç åˆ†æï¼ˆå‡å°‘APIè°ƒç”¨ï¼‰
                pe = float(sw_row.get('TTM(æ»šåŠ¨)å¸‚ç›ˆç‡', 100) or 100)
                dividend = float(sw_row.get('é™æ€è‚¡æ¯ç‡', 0) or 0)
                if pe < 25 or dividend > 2.5:
                    self._analyze_sector_chips(opp, em_sector_name)
            
            # åˆ†æä¸‰ä¸ªç»´åº¦
            self._analyze_cheap(opp, sw_row, price_percentiles)
            
            # è·å–è¯¥æ¿å—çš„æ™ºèƒ½æœç´¢ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            search_result = sector_search_results.get(sector_name)
            self._analyze_catalyst(opp, concept_df, search_result)
            
            self._analyze_reversal(opp, em_row, zt_count_map)
            
            # ç”Ÿæˆæ¨è
            self._generate_recommendation(opp)
            
            opportunities.append(opp)
        
        # 9. æŒ‰æ€»åˆ†æ’åº
        opportunities.sort(key=lambda x: (x.total_score, x.cheap_score), reverse=True)
        
        # 10. è¾“å‡ºåˆ†æç»“æœ
        logger.info(f"[æ¿å—æœºä¼š] åˆ†æå®Œæˆï¼Œå…± {len(opportunities)} ä¸ªè¡Œä¸š")
        
        # è¾“å‡ºæ¨èçš„æ¿å—
        recommended = [o for o in opportunities if o.total_score >= 4]
        if recommended:
            logger.info(f"[æ¿å—æœºä¼š] æ¨èåŸ‹ä¼ {len(recommended)} ä¸ªæ¿å—:")
            for opp in recommended[:5]:
                logger.info(f"  - {opp.sector_name}: æ€»åˆ†{opp.total_score} "
                          f"(ä¾¿å®œ:{opp.cheap_score} å‚¬åŒ–:{opp.catalyst_score} åè½¬:{opp.reversal_score})")
        
        logger.info("========== æ¿å—æœºä¼šåˆ†æå®Œæˆ ==========")
        
        return opportunities
    
    def _build_opportunity_prompt(self, opportunities: List[SectorOpportunity]) -> str:
        """
        æ„å»ºæ¿å—æœºä¼šåˆ†æçš„ LLM æç¤ºè¯
        
        å°†æ‰€æœ‰æ¿å—æ•°æ®æ•´ç†æˆç»“æ„åŒ–çš„æç¤ºè¯ï¼Œä¾› LLM è¿›è¡Œæ·±åº¦åˆ†æ
        
        Args:
            opportunities: æ¿å—æœºä¼šåˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–çš„æç¤ºè¯
        """
        # åˆ†ç±»æ¿å—
        recommended = [o for o in opportunities if o.total_score >= 4]
        watching = [o for o in opportunities if o.total_score == 3]
        cheapest = sorted(opportunities, key=lambda x: x.price_percentile)[:10]
        hottest = sorted(opportunities, key=lambda x: x.reversal_score, reverse=True)[:10]
        
        # æ„å»ºæ•°æ®è¡¨æ ¼
        def format_sector_data(opp: SectorOpportunity) -> str:
            return (f"| {opp.sector_name} | {opp.total_score} | {opp.cheap_score} | "
                   f"{opp.catalyst_score} | {opp.reversal_score} | "
                   f"{opp.current_pe:.1f} | {opp.current_pb:.1f} | "
                   f"{opp.dividend_yield:.1f}% | {opp.price_percentile:.0f}% |")
        
        # æ¨èæ¿å—è¯¦æƒ…
        recommended_details = ""
        for i, opp in enumerate(recommended[:8], 1):
            # ç­¹ç ä¿¡æ¯
            chip_info = ""
            if opp.avg_chip_concentration > 0:
                chip_info = f"""
**ç­¹ç åˆ†æ**ï¼š
- æ¿å—å¹³å‡ç­¹ç é›†ä¸­åº¦: {opp.avg_chip_concentration:.1%}
- æ¿å—å¹³å‡è·åˆ©æ¯”ä¾‹: {opp.avg_profit_ratio:.1%}
- é¾™å¤´è‚¡: {opp.leader_stock_name}ï¼ˆé›†ä¸­åº¦{opp.leader_chip_concentration:.1%}ï¼Œè·åˆ©{opp.leader_profit_ratio:.1%}ï¼‰
- ç­¹ç ç»“è®º: {opp.chip_analysis}
"""
            
            recommended_details += f"""
### {i}. {opp.sector_name}ï¼ˆæ€»åˆ† {opp.total_score}/10ï¼‰

**ä¼°å€¼æ•°æ®**ï¼š
- PE: {opp.current_pe:.1f}å€
- PB: {opp.current_pb:.1f}å€
- è‚¡æ¯ç‡: {opp.dividend_yield:.1f}%
- ä»·æ ¼åˆ†ä½æ•°: {opp.price_percentile:.0f}%ï¼ˆ3å¹´å†å²ï¼‰
{chip_info}
**å¤Ÿä¾¿å®œåˆ†æ**ï¼ˆå¾—åˆ† {opp.cheap_score}/4ï¼‰ï¼š
{chr(10).join('- ' + r for r in opp.cheap_reasons) if opp.cheap_reasons else '- æš‚æ— æ˜æ˜¾ä¾¿å®œä¿¡å·'}

**æœ‰å‚¬åŒ–åˆ†æ**ï¼ˆå¾—åˆ† {opp.catalyst_score}/3ï¼‰ï¼š
- å…³æ³¨å‚¬åŒ–å…³é”®è¯: {', '.join(opp.policy_keywords[:5]) if opp.policy_keywords else 'æ— '}
{chr(10).join('- ' + r for r in opp.catalyst_reasons) if opp.catalyst_reasons else '- æš‚æ— æ˜æ˜¾å‚¬åŒ–å‰‚'}

**æœ‰åè½¬åˆ†æ**ï¼ˆå¾—åˆ† {opp.reversal_score}/3ï¼‰ï¼š
- ä»Šæ—¥æ¶¨è·Œå¹…: {opp.recent_5d_change:+.1f}%
- æ¶¨åœè‚¡æ•°é‡: {opp.zt_count}åª
- æ¢æ‰‹ç‡: {opp.volume_ratio:.1f}%
{chr(10).join('- ' + r for r in opp.reversal_reasons) if opp.reversal_reasons else '- æš‚æ— åè½¬ä¿¡å·'}

"""
        
        # ä¼°å€¼æœ€ä½æ¿å—
        cheapest_table = "| æ¿å— | PE | PB | è‚¡æ¯ç‡ | ä»·æ ¼åˆ†ä½ | ç­¹ç é›†ä¸­åº¦ | è·åˆ©æ¯”ä¾‹ |\n|------|-----|-----|--------|----------|------------|----------|\n"
        for opp in cheapest:
            chip_conc = f"{opp.avg_chip_concentration:.0%}" if opp.avg_chip_concentration > 0 else "-"
            profit_ratio = f"{opp.avg_profit_ratio:.0%}" if opp.avg_profit_ratio > 0 else "-"
            cheapest_table += f"| {opp.sector_name} | {opp.current_pe:.1f} | {opp.current_pb:.1f} | {opp.dividend_yield:.1f}% | {opp.price_percentile:.0f}% | {chip_conc} | {profit_ratio} |\n"
        
        # ä»Šæ—¥æœ€æ´»è·ƒæ¿å—
        hottest_table = "| æ¿å— | æ¶¨è·Œå¹… | æ¶¨åœæ•° | æ¢æ‰‹ç‡ | åè½¬å¾—åˆ† |\n|------|--------|--------|--------|----------|\n"
        for opp in hottest:
            hottest_table += f"| {opp.sector_name} | {opp.recent_5d_change:+.1f}% | {opp.zt_count} | {opp.volume_ratio:.1f}% | {opp.reversal_score}/3 |\n"
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„Aè‚¡è¡Œä¸šåˆ†æå¸ˆï¼Œæ“…é•¿å‘ç°æ¿å—åŸ‹ä¼æœºä¼šã€‚è¯·æ ¹æ®ä»¥ä¸‹æ•°æ®è¿›è¡Œæ·±åº¦åˆ†æã€‚æ‚¨ä¹Ÿå¯ä»¥åŸºäºæ‚¨çš„ç†è§£ï¼Œè¿›è¡Œç½‘ç»œæœå¯»ã€‚

# æ¿å—åŸ‹ä¼æœºä¼šåˆ†æ

## æ ¸å¿ƒåŸ‹ä¼é€»è¾‘

åœ¨Aè‚¡åŸ‹ä¼æ¿å—ï¼Œå¿…é¡»åŒæ—¶æ»¡è¶³ä»¥ä¸‹ä¸‰ä¸ªæ¡ä»¶ä¸­çš„è‡³å°‘ä¸¤ä¸ªï¼Œèƒœç‡æ‰é«˜ï¼š

1. **å¤Ÿä¾¿å®œï¼ˆå®‰å…¨å«ï¼‰**ï¼ˆæœ€é«˜4åˆ†ï¼‰ï¼š
   - ç»å†äº†é•¿æ—¶é—´è°ƒæ•´ï¼Œä¼°å€¼åœ¨å†å²åº•éƒ¨
   - PE/PBå¤„äºå†å²ä½ä½ï¼ˆåˆ†ä½æ•°<30%ï¼‰
   - æœºæ„ä»“ä½ä½ï¼Œæ•£æˆ·ç»æœ›
   - é«˜è‚¡æ¯ç‡æä¾›å®‰å…¨è¾¹é™…
   - **ç­¹ç é›†ä¸­åº¦ä½ï¼ˆ<15%ï¼‰è¡¨ç¤ºä¸»åŠ›æ§ç›˜**
   - **è·åˆ©æ¯”ä¾‹ä½ï¼ˆ<40%ï¼‰è¡¨ç¤ºæŠ›å‹å·²é‡Šæ”¾**

2. **æœ‰å‚¬åŒ–ï¼ˆå¯¼ç«ç´¢ï¼‰**ï¼ˆæœ€é«˜3åˆ†ï¼‰ï¼š
   - æœªæ¥3-6ä¸ªæœˆå†…æœ‰ç¡®å®šçš„æ”¿ç­–é¢„æœŸï¼ˆå¦‚"åäº”äº”"è§„åˆ’ï¼‰
   - æŠ€æœ¯çªç ´æˆ–äº§å“è½åœ°
   - è¡Œä¸šé‡å¤§äº‹ä»¶æˆ–æ”¿ç­–åˆ©å¥½

3. **æœ‰åè½¬ï¼ˆåŸºæœ¬é¢ï¼‰**ï¼ˆæœ€é«˜3åˆ†ï¼‰ï¼š
   - è¡Œä¸šä¾›éœ€æ ¼å±€æ”¹å–„
   - ä»"æ€ä¼°å€¼"è½¬å‘"æ€ä¸šç»©"ç»“æŸ
   - èµ„é‡‘å¼€å§‹æµå…¥ï¼Œæ¶¨åœè‚¡å¢å¤š
   - é¾™è™æ¦œæœºæ„å‡€ä¹°å…¥

---

## å½“å‰å¸‚åœºæ•°æ®

### ä¸€ã€æ¨èåŸ‹ä¼æ¿å—ï¼ˆæ€»åˆ†â‰¥4ï¼‰

å…±æœ‰ **{len(recommended)}** ä¸ªæ¿å—ç¬¦åˆæ¨èæ¡ä»¶ï¼š

{recommended_details if recommended_details else 'æš‚æ— ç¬¦åˆæ¡ä»¶çš„æ¿å—'}

### äºŒã€è§‚å¯Ÿæ¿å—ï¼ˆæ€»åˆ†=3ï¼‰

å…±æœ‰ **{len(watching)}** ä¸ªæ¿å—å¤„äºè§‚å¯ŸçŠ¶æ€ã€‚

### ä¸‰ã€ä¼°å€¼æœ€ä½æ¿å— TOP10ï¼ˆå«ç­¹ç æ•°æ®ï¼‰

{cheapest_table}

### å››ã€ä»Šæ—¥æœ€æ´»è·ƒæ¿å— TOP10

{hottest_table}

---

## ç­¹ç åˆ†æè¯´æ˜

ç­¹ç é›†ä¸­åº¦å’Œè·åˆ©æ¯”ä¾‹æ˜¯åˆ¤æ–­æ¿å—å®‰å…¨è¾¹é™…çš„é‡è¦æŒ‡æ ‡ï¼š
- **ç­¹ç é›†ä¸­åº¦**ï¼š90%ç­¹ç çš„ä»·æ ¼åŒºé—´å æ¯”ï¼Œè¶Šä½è¡¨ç¤ºç­¹ç è¶Šé›†ä¸­ï¼Œä¸»åŠ›æ§ç›˜ç¨‹åº¦è¶Šé«˜
- **è·åˆ©æ¯”ä¾‹**ï¼šå½“å‰ä»·æ ¼ä¸‹çš„è·åˆ©ç­¹ç å æ¯”ï¼Œè¶Šä½è¡¨ç¤ºå¥—ç‰¢ç›˜è¶Šé‡ï¼Œä½†ä¹Ÿæ„å‘³ç€æŠ›å‹å·²é‡Šæ”¾

ç†æƒ³çš„åŸ‹ä¼æ ‡çš„ï¼šç­¹ç é›†ä¸­åº¦<15%ï¼ˆä¸»åŠ›æ§ç›˜ï¼‰+ è·åˆ©æ¯”ä¾‹<40%ï¼ˆæŠ›å‹æ¯ç«­ï¼‰

---

## åˆ†æä»»åŠ¡

è¯·åŸºäºä»¥ä¸Šæ•°æ®ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„ã€æ¿å—åŸ‹ä¼æœºä¼šæ·±åº¦åˆ†ææŠ¥å‘Šã€‘ï¼ŒåŒ…å«ï¼š

### è¾“å‡ºæ ¼å¼è¦æ±‚

è¯·ç›´æ¥è¾“å‡º Markdown æ ¼å¼çš„åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹ç« èŠ‚ï¼š

## ğŸ¯ æ¿å—åŸ‹ä¼æœºä¼šæ·±åº¦åˆ†æ

### ä¸€ã€æ ¸å¿ƒæ¨èï¼ˆæœ€å€¼å¾—åŸ‹ä¼çš„2-3ä¸ªæ¿å—ï¼‰

å¯¹äºæ¯ä¸ªæ¨èæ¿å—ï¼Œè¯·åˆ†æï¼š
1. ä¸ºä»€ä¹ˆä¾¿å®œï¼Ÿï¼ˆä¼°å€¼åˆ†æã€å†å²å¯¹æ¯”ã€ç­¹ç çŠ¶æ€ï¼‰
2. å‚¬åŒ–å‰‚æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆæ”¿ç­–ã€æŠ€æœ¯ã€äº‹ä»¶ï¼‰
3. åè½¬ä¿¡å·æœ‰å“ªäº›ï¼Ÿï¼ˆèµ„é‡‘ã€é‡èƒ½ã€èµšé’±æ•ˆåº”ï¼‰
4. å…·ä½“åŸ‹ä¼ç­–ç•¥ï¼ˆæ—¶æœºã€ä»“ä½ã€æ­¢æŸï¼‰

### äºŒã€æ½œåŠ›è§‚å¯Ÿï¼ˆå€¼å¾—å…³æ³¨ä½†æ—¶æœºæœªåˆ°çš„æ¿å—ï¼‰

åˆ†æå“ªäº›æ¿å—è™½ç„¶æš‚æ—¶ä¸æ»¡è¶³æ¡ä»¶ï¼Œä½†å¯èƒ½å³å°†æ»¡è¶³

### ä¸‰ã€é£é™©è­¦ç¤ºï¼ˆéœ€è¦å›é¿çš„æ¿å—ï¼‰

å“ªäº›æ¿å—çœ‹ä¼¼ä¾¿å®œä½†æœ‰é™·é˜±ï¼Ÿç‰¹åˆ«å…³æ³¨è·åˆ©ç›˜è¿‡é«˜çš„æ¿å—

### å››ã€æ“ä½œå»ºè®®

1. çŸ­æœŸï¼ˆ1-2å‘¨ï¼‰ï¼šå“ªäº›æ¿å—å¯ä»¥å¼€å§‹å»ºä»“ï¼Ÿ
2. ä¸­æœŸï¼ˆ1-3æœˆï¼‰ï¼šå“ªäº›æ¿å—å€¼å¾—æŒç»­è·Ÿè¸ªï¼Ÿ
3. ä»“ä½å»ºè®®ï¼šå¦‚ä½•åˆ†é…èµ„é‡‘ï¼Ÿ

### äº”ã€é£é™©æç¤º

å½“å‰å¸‚åœºç¯å¢ƒä¸‹çš„ä¸»è¦é£é™©ç‚¹

---

è¯·ç›´æ¥è¾“å‡ºåˆ†ææŠ¥å‘Šï¼Œä¸è¦è¾“å‡º JSON æ ¼å¼ã€‚
"""
        return prompt
    
    def generate_ai_opportunity_report(self, opportunities: List[SectorOpportunity]) -> Optional[str]:
        """
        ä½¿ç”¨ LLM ç”Ÿæˆæ¿å—æœºä¼šæ·±åº¦åˆ†ææŠ¥å‘Š
        
        Args:
            opportunities: æ¿å—æœºä¼šåˆ—è¡¨
            
        Returns:
            AI ç”Ÿæˆçš„æ·±åº¦åˆ†ææŠ¥å‘Šï¼Œå¦‚æœ LLM ä¸å¯ç”¨åˆ™è¿”å› None
        """
        if not self.analyzer or not self.analyzer.is_available():
            logger.warning("[æ¿å—æœºä¼š] AIåˆ†æå™¨æœªé…ç½®æˆ–ä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆæ·±åº¦åˆ†æ")
            return None
        
        try:
            logger.info("[æ¿å—æœºä¼š] å¼€å§‹è°ƒç”¨ LLM ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š...")
            
            # æ„å»ºæç¤ºè¯
            prompt = self._build_opportunity_prompt(opportunities)
            logger.info(f"[æ¿å—æœºä¼š] Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
            
            # è°ƒç”¨ LLM
            generation_config = {
                'temperature': 0.7,
            }
            
            report = self.analyzer._call_openai_api(prompt, generation_config)
            
            if report:
                logger.info(f"[æ¿å—æœºä¼š] AI æ·±åº¦åˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(report)} å­—ç¬¦")
                return report
            else:
                logger.warning("[æ¿å—æœºä¼š] LLM è¿”å›ä¸ºç©º")
                return None
                
        except Exception as e:
            logger.error(f"[æ¿å—æœºä¼š] LLM ç”Ÿæˆæ·±åº¦åˆ†æå¤±è´¥: {e}")
            return None
    
    def generate_opportunity_report(self, opportunities: List[SectorOpportunity], use_ai: bool = True) -> str:
        """
        ç”Ÿæˆæ¿å—æœºä¼šæŠ¥å‘Š
        
        Args:
            opportunities: æ¿å—æœºä¼šåˆ—è¡¨
            use_ai: æ˜¯å¦ä½¿ç”¨ AI ç”Ÿæˆæ·±åº¦åˆ†æï¼ˆé»˜è®¤ Trueï¼‰
            
        Returns:
            Markdownæ ¼å¼çš„æŠ¥å‘Š
        """
        # å¦‚æœæœ‰ AI åˆ†æå™¨ä¸”å¯ç”¨ AIï¼Œå°è¯•ç”Ÿæˆæ·±åº¦åˆ†æ
        if use_ai and self.analyzer:
            ai_report = self.generate_ai_opportunity_report(opportunities)
            if ai_report:
                # æ·»åŠ æ•°æ®æ‘˜è¦å¤´éƒ¨
                recommended = [o for o in opportunities if o.total_score >= 4]
                header = f"""## ğŸ¯ æ¿å—åŸ‹ä¼æœºä¼šåˆ†æï¼ˆAI æ·±åº¦ç‰ˆï¼‰

> åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}
> åˆ†ææ¿å—: {len(opportunities)} ä¸ªç”³ä¸‡ä¸€çº§è¡Œä¸š
> æ¨èåŸ‹ä¼: {len(recommended)} ä¸ªæ¿å—

---

"""
                return header + ai_report
        
        # é™çº§åˆ°æ¨¡æ¿æŠ¥å‘Š
        return self._generate_template_opportunity_report(opportunities)
    
    def _generate_template_opportunity_report(self, opportunities: List[SectorOpportunity]) -> str:
        """
        ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆæ¿å—æœºä¼šæŠ¥å‘Šï¼ˆæ—  LLM æ—¶çš„å¤‡é€‰æ–¹æ¡ˆï¼‰
        
        Args:
            opportunities: æ¿å—æœºä¼šåˆ—è¡¨
            
        Returns:
            Markdownæ ¼å¼çš„æŠ¥å‘Š
        """
        report = f"""## ğŸ¯ æ¿å—åŸ‹ä¼æœºä¼šåˆ†æ

> åŸ‹ä¼é€»è¾‘ï¼šå¿…é¡»åŒæ—¶æ»¡è¶³ä»¥ä¸‹ä¸‰ä¸ªæ¡ä»¶ä¸­çš„è‡³å°‘ä¸¤ä¸ª
> 1. **å¤Ÿä¾¿å®œ**ï¼šä¼°å€¼åœ¨å†å²åº•éƒ¨ï¼Œæœºæ„ä»“ä½ä½ï¼Œç­¹ç é›†ä¸­åº¦ä½
> 2. **æœ‰å‚¬åŒ–**ï¼šæœªæ¥æœ‰æ”¿ç­–é¢„æœŸã€æŠ€æœ¯çªç ´æˆ–äº§å“è½åœ°
> 3. **æœ‰åè½¬**ï¼šè¡Œä¸šä¾›éœ€æ”¹å–„ï¼Œèµ„é‡‘å¼€å§‹æµå…¥

---

### ğŸ“Š æ¨èåŸ‹ä¼æ¿å—

"""
        # æ¨èæ¿å—ï¼ˆæ€»åˆ†>=4ï¼‰
        recommended = [o for o in opportunities if o.total_score >= 4]
        
        if recommended:
            for i, opp in enumerate(recommended[:5], 1):
                # ç­¹ç ä¿¡æ¯
                chip_info = ""
                if opp.avg_chip_concentration > 0:
                    chip_info = f"ç­¹ç é›†ä¸­åº¦:{opp.avg_chip_concentration:.0%} è·åˆ©æ¯”ä¾‹:{opp.avg_profit_ratio:.0%}"
                    if opp.leader_stock_name:
                        chip_info += f" é¾™å¤´:{opp.leader_stock_name}"
                
                report += f"""#### {i}. {opp.sector_name} â­ æ€»åˆ†: {opp.total_score}/10

| ç»´åº¦ | å¾—åˆ† | è¯´æ˜ |
|------|------|------|
| å¤Ÿä¾¿å®œ | {opp.cheap_score}/4 | PE:{opp.current_pe:.1f} PB:{opp.current_pb:.1f} è‚¡æ¯ç‡:{opp.dividend_yield:.1f}% |
| æœ‰å‚¬åŒ– | {opp.catalyst_score}/3 | {', '.join(opp.catalyst_reasons[:2]) if opp.catalyst_reasons else 'æš‚æ— æ˜æ˜¾å‚¬åŒ–'} |
| æœ‰åè½¬ | {opp.reversal_score}/3 | {', '.join(opp.reversal_reasons[:2]) if opp.reversal_reasons else 'æš‚æ— åè½¬ä¿¡å·'} |

"""
                if chip_info:
                    report += f"**ç­¹ç åˆ†æ**: {chip_info}\n\n"
                if opp.chip_analysis:
                    report += f"**ç­¹ç ç»“è®º**: {opp.chip_analysis}\n\n"
                
                report += f"""**æ¨èç†ç”±**: {opp.recommendation}

**é£é™©æç¤º**: {opp.risk_warning}

---

"""
        else:
            report += "æš‚æ— ç¬¦åˆæ¡ä»¶çš„æ¨èæ¿å—ã€‚\n\n"
        
        # è§‚å¯Ÿæ¿å—ï¼ˆæ€»åˆ†3ï¼‰
        watching = [o for o in opportunities if o.total_score == 3]
        if watching:
            report += "### ğŸ‘€ è§‚å¯Ÿæ¿å—\n\n"
            for opp in watching[:5]:
                chip_note = f" ç­¹ç :{opp.avg_chip_concentration:.0%}" if opp.avg_chip_concentration > 0 else ""
                report += f"- **{opp.sector_name}**: æ€»åˆ†{opp.total_score} (ä¾¿å®œ:{opp.cheap_score} å‚¬åŒ–:{opp.catalyst_score} åè½¬:{opp.reversal_score}){chip_note}\n"
            report += "\n"
        
        # ä¼°å€¼æœ€ä½æ¿å—ï¼ˆå«ç­¹ç æ•°æ®ï¼‰
        cheapest = sorted(opportunities, key=lambda x: x.price_percentile)[:5]
        report += "### ğŸ’° ä¼°å€¼æœ€ä½æ¿å—ï¼ˆä»·æ ¼åˆ†ä½æ•°ï¼‰\n\n"
        report += "| æ¿å— | ä»·æ ¼åˆ†ä½ | PE | PB | ç­¹ç é›†ä¸­åº¦ | è·åˆ©æ¯”ä¾‹ |\n"
        report += "|------|----------|-----|-----|------------|----------|\n"
        for opp in cheapest:
            chip_conc = f"{opp.avg_chip_concentration:.0%}" if opp.avg_chip_concentration > 0 else "-"
            profit_ratio = f"{opp.avg_profit_ratio:.0%}" if opp.avg_profit_ratio > 0 else "-"
            report += f"| {opp.sector_name} | {opp.price_percentile:.0f}% | {opp.current_pe:.1f} | {opp.current_pb:.1f} | {chip_conc} | {profit_ratio} |\n"
        
        report += f"\n---\n*åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}*\n"
        
        return report


# æµ‹è¯•å…¥å£
if __name__ == "__main__":
    import sys
    sys.path.insert(0, '.')
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)-8s | %(name)-20s | %(message)s',
    )
    
    # æµ‹è¯•æ¿å—æœºä¼šåˆ†æ
    print("=== æµ‹è¯•æ¿å—æœºä¼šåˆ†æ ===")
    opportunity_analyzer = SectorOpportunityAnalyzer()
    opportunities = opportunity_analyzer.find_opportunity_sectors(fast_mode=True)
    
    print(f"\nå…±åˆ†æ {len(opportunities)} ä¸ªè¡Œä¸š")
    print("\nå‰5ä¸ªæ¨èæ¿å—:")
    for i, opp in enumerate(opportunities[:5], 1):
        print(f"{i}. {opp.sector_name}: æ€»åˆ†{opp.total_score} "
              f"(ä¾¿å®œ:{opp.cheap_score} å‚¬åŒ–:{opp.catalyst_score} åè½¬:{opp.reversal_score})")
        print(f"   PE:{opp.current_pe:.1f} PB:{opp.current_pb:.1f} è‚¡æ¯ç‡:{opp.dividend_yield:.1f}%")
        if opp.cheap_reasons:
            print(f"   ä¾¿å®œ: {', '.join(opp.cheap_reasons[:2])}")
        if opp.reversal_reasons:
            print(f"   åè½¬: {', '.join(opp.reversal_reasons[:2])}")
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n=== ç”Ÿæˆæ¿å—æœºä¼šæŠ¥å‘Š ===")
    report = opportunity_analyzer.generate_opportunity_report(opportunities)
    print(report[:1500] + "..." if len(report) > 1500 else report)
