# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ - æœç´¢æœåŠ¡æ¨¡å—
===================================

èŒè´£ï¼š
1. æä¾›ç»Ÿä¸€çš„æ–°é—»æœç´¢æ¥å£
2. æ”¯æŒ Tavily å’Œ SerpAPI ä¸¤ç§æœç´¢å¼•æ“
3. å¤š Key è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»
4. æœç´¢ç»“æœç¼“å­˜å’Œæ ¼å¼åŒ–
"""

import logging
import random
import time
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Dict, Any, Optional
from itertools import cycle

logger = logging.getLogger(__name__)


@dataclass
class SearchResult:
    """æœç´¢ç»“æœæ•°æ®ç±»"""
    title: str
    snippet: str  # æ‘˜è¦
    url: str
    source: str  # æ¥æºç½‘ç«™
    published_date: Optional[str] = None
    
    def to_text(self) -> str:
        """è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼"""
        date_str = f" ({self.published_date})" if self.published_date else ""
        return f"ã€{self.source}ã€‘{self.title}{date_str}\n{self.snippet}"


@dataclass 
class SearchResponse:
    """æœç´¢å“åº”"""
    query: str
    results: List[SearchResult]
    provider: str  # ä½¿ç”¨çš„æœç´¢å¼•æ“
    success: bool = True
    error_message: Optional[str] = None
    search_time: float = 0.0  # æœç´¢è€—æ—¶ï¼ˆç§’ï¼‰
    
    def to_context(self, max_results: int = 5) -> str:
        """å°†æœç´¢ç»“æœè½¬æ¢ä¸ºå¯ç”¨äº AI åˆ†æçš„ä¸Šä¸‹æ–‡"""
        if not self.success or not self.results:
            return f"æœç´¢ '{self.query}' æœªæ‰¾åˆ°ç›¸å…³ç»“æœã€‚"
        
        lines = [f"ã€{self.query} æœç´¢ç»“æœã€‘ï¼ˆæ¥æºï¼š{self.provider}ï¼‰"]
        for i, result in enumerate(self.results[:max_results], 1):
            lines.append(f"\n{i}. {result.to_text()}")
        
        return "\n".join(lines)


class BaseSearchProvider(ABC):
    """æœç´¢å¼•æ“åŸºç±»"""
    
    def __init__(self, api_keys: List[str], name: str):
        """
        åˆå§‹åŒ–æœç´¢å¼•æ“
        
        Args:
            api_keys: API Key åˆ—è¡¨ï¼ˆæ”¯æŒå¤šä¸ª key è´Ÿè½½å‡è¡¡ï¼‰
            name: æœç´¢å¼•æ“åç§°
        """
        self._api_keys = api_keys
        self._name = name
        self._key_cycle = cycle(api_keys) if api_keys else None
        self._key_usage: Dict[str, int] = {key: 0 for key in api_keys}
        self._key_errors: Dict[str, int] = {key: 0 for key in api_keys}
    
    @property
    def name(self) -> str:
        return self._name
    
    @property
    def is_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ API Key"""
        return bool(self._api_keys)
    
    def _get_next_key(self) -> Optional[str]:
        """
        è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„ API Keyï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
        
        ç­–ç•¥ï¼šè½®è¯¢ + è·³è¿‡é”™è¯¯è¿‡å¤šçš„ key
        """
        if not self._key_cycle:
            return None
        
        # æœ€å¤šå°è¯•æ‰€æœ‰ key
        for _ in range(len(self._api_keys)):
            key = next(self._key_cycle)
            # è·³è¿‡é”™è¯¯æ¬¡æ•°è¿‡å¤šçš„ keyï¼ˆè¶…è¿‡ 3 æ¬¡ï¼‰
            if self._key_errors.get(key, 0) < 3:
                return key
        
        # æ‰€æœ‰ key éƒ½æœ‰é—®é¢˜ï¼Œé‡ç½®é”™è¯¯è®¡æ•°å¹¶è¿”å›ç¬¬ä¸€ä¸ª
        logger.warning(f"[{self._name}] æ‰€æœ‰ API Key éƒ½æœ‰é”™è¯¯è®°å½•ï¼Œé‡ç½®é”™è¯¯è®¡æ•°")
        self._key_errors = {key: 0 for key in self._api_keys}
        return self._api_keys[0] if self._api_keys else None
    
    def _record_success(self, key: str) -> None:
        """è®°å½•æˆåŠŸä½¿ç”¨"""
        self._key_usage[key] = self._key_usage.get(key, 0) + 1
        # æˆåŠŸåå‡å°‘é”™è¯¯è®¡æ•°
        if key in self._key_errors and self._key_errors[key] > 0:
            self._key_errors[key] -= 1
    
    def _record_error(self, key: str) -> None:
        """è®°å½•é”™è¯¯"""
        self._key_errors[key] = self._key_errors.get(key, 0) + 1
        logger.warning(f"[{self._name}] API Key {key[:8]}... é”™è¯¯è®¡æ•°: {self._key_errors[key]}")
    
    @abstractmethod
    def _do_search(self, query: str, api_key: str, max_results: int) -> SearchResponse:
        """æ‰§è¡Œæœç´¢ï¼ˆå­ç±»å®ç°ï¼‰"""
        pass
    
    def search(self, query: str, max_results: int = 5) -> SearchResponse:
        """
        æ‰§è¡Œæœç´¢
        
        Args:
            query: æœç´¢å…³é”®è¯
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
            
        Returns:
            SearchResponse å¯¹è±¡
        """
        api_key = self._get_next_key()
        if not api_key:
            return SearchResponse(
                query=query,
                results=[],
                provider=self._name,
                success=False,
                error_message=f"{self._name} æœªé…ç½® API Key"
            )
        
        start_time = time.time()
        try:
            response = self._do_search(query, api_key, max_results)
            response.search_time = time.time() - start_time
            
            if response.success:
                self._record_success(api_key)
                logger.info(f"[{self._name}] æœç´¢ '{query}' æˆåŠŸï¼Œè¿”å› {len(response.results)} æ¡ç»“æœï¼Œè€—æ—¶ {response.search_time:.2f}s")
            else:
                self._record_error(api_key)
            
            return response
            
        except Exception as e:
            self._record_error(api_key)
            elapsed = time.time() - start_time
            logger.error(f"[{self._name}] æœç´¢ '{query}' å¤±è´¥: {e}")
            return SearchResponse(
                query=query,
                results=[],
                provider=self._name,
                success=False,
                error_message=str(e),
                search_time=elapsed
            )


class TavilySearchProvider(BaseSearchProvider):
    """
    Tavily æœç´¢å¼•æ“
    
    ç‰¹ç‚¹ï¼š
    - ä¸“ä¸º AI/LLM ä¼˜åŒ–çš„æœç´¢ API
    - å…è´¹ç‰ˆæ¯æœˆ 1000 æ¬¡è¯·æ±‚
    - è¿”å›ç»“æ„åŒ–çš„æœç´¢ç»“æœ
    
    æ–‡æ¡£ï¼šhttps://docs.tavily.com/
    """
    
    def __init__(self, api_keys: List[str]):
        super().__init__(api_keys, "Tavily")
    
    def _do_search(self, query: str, api_key: str, max_results: int) -> SearchResponse:
        """æ‰§è¡Œ Tavily æœç´¢"""
        try:
            from tavily import TavilyClient
        except ImportError:
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message="tavily-python æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install tavily-python"
            )
        
        try:
            client = TavilyClient(api_key=api_key)
            
            # æ‰§è¡Œæœç´¢ï¼ˆä¼˜åŒ–ï¼šä½¿ç”¨advancedæ·±åº¦ã€é™åˆ¶æœ€è¿‘7å¤©ï¼‰
            response = client.search(
                query=query,
                search_depth="advanced",  # advanced è·å–æ›´å¤šç»“æœ
                max_results=max_results,
                include_answer=False,
                include_raw_content=False,
                days=7,  # åªæœç´¢æœ€è¿‘7å¤©çš„å†…å®¹
            )
            
            # è®°å½•åŸå§‹å“åº”åˆ°æ—¥å¿—
            logger.info(f"[Tavily] æœç´¢å®Œæˆï¼Œquery='{query}', è¿”å› {len(response.get('results', []))} æ¡ç»“æœ")
            logger.debug(f"[Tavily] åŸå§‹å“åº”: {response}")
            
            # è§£æç»“æœ
            results = []
            for item in response.get('results', []):
                results.append(SearchResult(
                    title=item.get('title', ''),
                    snippet=item.get('content', '')[:500],  # æˆªå–å‰500å­—
                    url=item.get('url', ''),
                    source=self._extract_domain(item.get('url', '')),
                    published_date=item.get('published_date'),
                ))
            
            return SearchResponse(
                query=query,
                results=results,
                provider=self.name,
                success=True,
            )
            
        except Exception as e:
            error_msg = str(e)
            # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢é—®é¢˜
            if 'rate limit' in error_msg.lower() or 'quota' in error_msg.lower():
                error_msg = f"API é…é¢å·²ç”¨å°½: {error_msg}"
            
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message=error_msg
            )
    
    @staticmethod
    def _extract_domain(url: str) -> str:
        """ä» URL æå–åŸŸåä½œä¸ºæ¥æº"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            domain = parsed.netloc.replace('www.', '')
            return domain or 'æœªçŸ¥æ¥æº'
        except:
            return 'æœªçŸ¥æ¥æº'


class SerpAPISearchProvider(BaseSearchProvider):
    """
    SerpAPI æœç´¢å¼•æ“
    
    ç‰¹ç‚¹ï¼š
    - æ”¯æŒ Googleã€Bingã€ç™¾åº¦ç­‰å¤šç§æœç´¢å¼•æ“
    - å…è´¹ç‰ˆæ¯æœˆ 100 æ¬¡è¯·æ±‚
    - è¿”å›çœŸå®çš„æœç´¢ç»“æœ
    
    æ–‡æ¡£ï¼šhttps://serpapi.com/
    """
    
    def __init__(self, api_keys: List[str]):
        super().__init__(api_keys, "SerpAPI")
    
    def _do_search(self, query: str, api_key: str, max_results: int) -> SearchResponse:
        """æ‰§è¡Œ SerpAPI æœç´¢"""
        try:
            from serpapi import GoogleSearch
        except ImportError:
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message="google-search-results æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install google-search-results"
            )
        
        try:
            # ä½¿ç”¨ç™¾åº¦æœç´¢ï¼ˆå¯¹ä¸­æ–‡è‚¡ç¥¨æ–°é—»æ›´å‹å¥½ï¼‰
            params = {
                "engine": "baidu",  # ä½¿ç”¨ç™¾åº¦æœç´¢
                "q": query,
                "api_key": api_key,
            }
            
            search = GoogleSearch(params)
            response = search.get_dict()
            
            # è®°å½•åŸå§‹å“åº”åˆ°æ—¥å¿—
            logger.debug(f"[SerpAPI] åŸå§‹å“åº” keys: {response.keys()}")
            
            # è§£æç»“æœ
            results = []
            organic_results = response.get('organic_results', [])
            
            for item in organic_results[:max_results]:
                results.append(SearchResult(
                    title=item.get('title', ''),
                    snippet=item.get('snippet', '')[:500],
                    url=item.get('link', ''),
                    source=item.get('source', self._extract_domain(item.get('link', ''))),
                    published_date=item.get('date'),
                ))
            
            return SearchResponse(
                query=query,
                results=results,
                provider=self.name,
                success=True,
            )
            
        except Exception as e:
            error_msg = str(e)
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message=error_msg
            )
    
    @staticmethod
    def _extract_domain(url: str) -> str:
        """ä» URL æå–åŸŸå"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            return parsed.netloc.replace('www.', '') or 'æœªçŸ¥æ¥æº'
        except:
            return 'æœªçŸ¥æ¥æº'


class BochaSearchProvider(BaseSearchProvider):
    """
    åšæŸ¥æœç´¢å¼•æ“
    
    ç‰¹ç‚¹ï¼š
    - ä¸“ä¸ºAIä¼˜åŒ–çš„ä¸­æ–‡æœç´¢API
    - ç»“æœå‡†ç¡®ã€æ‘˜è¦å®Œæ•´
    - æ”¯æŒæ—¶é—´èŒƒå›´è¿‡æ»¤å’ŒAIæ‘˜è¦
    - å…¼å®¹Bing Search APIæ ¼å¼
    
    æ–‡æ¡£ï¼šhttps://bocha-ai.feishu.cn/wiki/RXEOw02rFiwzGSkd9mUcqoeAnNK
    """
    
    def __init__(self, api_keys: List[str]):
        super().__init__(api_keys, "Bocha")
    
    def _do_search(self, query: str, api_key: str, max_results: int) -> SearchResponse:
        """æ‰§è¡ŒåšæŸ¥æœç´¢"""
        try:
            import requests
        except ImportError:
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message="requests æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install requests"
            )
        
        try:
            # API ç«¯ç‚¹
            url = "https://api.bocha.cn/v1/web-search"
            
            # è¯·æ±‚å¤´
            headers = {
                'Authorization': f'Bearer {api_key}',
                'Content-Type': 'application/json'
            }
            
            # è¯·æ±‚å‚æ•°ï¼ˆä¸¥æ ¼æŒ‰ç…§APIæ–‡æ¡£ï¼‰
            payload = {
                "query": query,
                "freshness": "oneMonth",  # æœç´¢è¿‘ä¸€ä¸ªæœˆï¼Œé€‚åˆæ•è·è´¢æŠ¥ã€å…¬å‘Šç­‰ä¿¡æ¯
                "summary": True,  # å¯ç”¨AIæ‘˜è¦
                "count": min(max_results, 50)  # æœ€å¤§50æ¡
            }
            
            # æ‰§è¡Œæœç´¢
            response = requests.post(url, headers=headers, json=payload, timeout=10)
            
            # æ£€æŸ¥HTTPçŠ¶æ€ç 
            if response.status_code != 200:
                # å°è¯•è§£æé”™è¯¯ä¿¡æ¯
                try:
                    if response.headers.get('content-type', '').startswith('application/json'):
                        error_data = response.json()
                        error_message = error_data.get('message', response.text)
                    else:
                        error_message = response.text
                except:
                    error_message = response.text
                
                # æ ¹æ®é”™è¯¯ç å¤„ç†
                if response.status_code == 403:
                    error_msg = f"ä½™é¢ä¸è¶³: {error_message}"
                elif response.status_code == 401:
                    error_msg = f"API KEYæ— æ•ˆ: {error_message}"
                elif response.status_code == 400:
                    error_msg = f"è¯·æ±‚å‚æ•°é”™è¯¯: {error_message}"
                elif response.status_code == 429:
                    error_msg = f"è¯·æ±‚é¢‘ç‡è¾¾åˆ°é™åˆ¶: {error_message}"
                else:
                    error_msg = f"HTTP {response.status_code}: {error_message}"
                
                logger.warning(f"[Bocha] æœç´¢å¤±è´¥: {error_msg}")
                
                return SearchResponse(
                    query=query,
                    results=[],
                    provider=self.name,
                    success=False,
                    error_message=error_msg
                )
            
            # è§£æå“åº”
            try:
                data = response.json()
            except ValueError as e:
                error_msg = f"å“åº”JSONè§£æå¤±è´¥: {str(e)}"
                logger.error(f"[Bocha] {error_msg}")
                return SearchResponse(
                    query=query,
                    results=[],
                    provider=self.name,
                    success=False,
                    error_message=error_msg
                )
            
            # æ£€æŸ¥å“åº”code
            if data.get('code') != 200:
                error_msg = data.get('msg') or f"APIè¿”å›é”™è¯¯ç : {data.get('code')}"
                return SearchResponse(
                    query=query,
                    results=[],
                    provider=self.name,
                    success=False,
                    error_message=error_msg
                )
            
            # è®°å½•åŸå§‹å“åº”åˆ°æ—¥å¿—
            logger.info(f"[Bocha] æœç´¢å®Œæˆï¼Œquery='{query}'")
            logger.debug(f"[Bocha] åŸå§‹å“åº”: {data}")
            
            # è§£ææœç´¢ç»“æœ
            results = []
            web_pages = data.get('data', {}).get('webPages', {})
            value_list = web_pages.get('value', [])
            
            for item in value_list[:max_results]:
                # ä¼˜å…ˆä½¿ç”¨summaryï¼ˆAIæ‘˜è¦ï¼‰ï¼Œfallbackåˆ°snippet
                snippet = item.get('summary') or item.get('snippet', '')
                
                # æˆªå–æ‘˜è¦é•¿åº¦
                if snippet:
                    snippet = snippet[:500]
                
                results.append(SearchResult(
                    title=item.get('name', ''),
                    snippet=snippet,
                    url=item.get('url', ''),
                    source=item.get('siteName') or self._extract_domain(item.get('url', '')),
                    published_date=item.get('datePublished'),  # UTC+8æ ¼å¼ï¼Œæ— éœ€è½¬æ¢
                ))
            
            logger.info(f"[Bocha] æˆåŠŸè§£æ {len(results)} æ¡ç»“æœ")
            
            return SearchResponse(
                query=query,
                results=results,
                provider=self.name,
                success=True,
            )
            
        except requests.exceptions.Timeout:
            error_msg = "è¯·æ±‚è¶…æ—¶"
            logger.error(f"[Bocha] {error_msg}")
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message=error_msg
            )
        except requests.exceptions.RequestException as e:
            error_msg = f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"
            logger.error(f"[Bocha] {error_msg}")
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message=error_msg
            )
        except Exception as e:
            error_msg = f"æœªçŸ¥é”™è¯¯: {str(e)}"
            logger.error(f"[Bocha] {error_msg}")
            return SearchResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message=error_msg
            )
    
    @staticmethod
    def _extract_domain(url: str) -> str:
        """ä» URL æå–åŸŸåä½œä¸ºæ¥æº"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            domain = parsed.netloc.replace('www.', '')
            return domain or 'æœªçŸ¥æ¥æº'
        except:
            return 'æœªçŸ¥æ¥æº'


class SearchService:
    """
    æœç´¢æœåŠ¡
    
    åŠŸèƒ½ï¼š
    1. ç®¡ç†å¤šä¸ªæœç´¢å¼•æ“
    2. è‡ªåŠ¨æ•…éšœè½¬ç§»
    3. ç»“æœèšåˆå’Œæ ¼å¼åŒ–
    """
    
    def __init__(
        self,
        bocha_keys: Optional[List[str]] = None,
        tavily_keys: Optional[List[str]] = None,
        serpapi_keys: Optional[List[str]] = None,
    ):
        """
        åˆå§‹åŒ–æœç´¢æœåŠ¡
        
        Args:
            bocha_keys: åšæŸ¥æœç´¢ API Key åˆ—è¡¨
            tavily_keys: Tavily API Key åˆ—è¡¨
            serpapi_keys: SerpAPI Key åˆ—è¡¨
        """
        self._providers: List[BaseSearchProvider] = []
        
        # åˆå§‹åŒ–æœç´¢å¼•æ“ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        # 1. Bocha ä¼˜å…ˆï¼ˆä¸­æ–‡æœç´¢ä¼˜åŒ–ï¼ŒAIæ‘˜è¦ï¼‰
        if bocha_keys:
            self._providers.append(BochaSearchProvider(bocha_keys))
            logger.info(f"å·²é…ç½® Bocha æœç´¢ï¼Œå…± {len(bocha_keys)} ä¸ª API Key")
        
        # 2. Tavilyï¼ˆå…è´¹é¢åº¦æ›´å¤šï¼Œæ¯æœˆ 1000 æ¬¡ï¼‰
        if tavily_keys:
            self._providers.append(TavilySearchProvider(tavily_keys))
            logger.info(f"å·²é…ç½® Tavily æœç´¢ï¼Œå…± {len(tavily_keys)} ä¸ª API Key")
        
        # 3. SerpAPI ä½œä¸ºå¤‡é€‰ï¼ˆæ¯æœˆ 100 æ¬¡ï¼‰
        if serpapi_keys:
            self._providers.append(SerpAPISearchProvider(serpapi_keys))
            logger.info(f"å·²é…ç½® SerpAPI æœç´¢ï¼Œå…± {len(serpapi_keys)} ä¸ª API Key")
        
        if not self._providers:
            logger.warning("æœªé…ç½®ä»»ä½•æœç´¢å¼•æ“ API Keyï¼Œæ–°é—»æœç´¢åŠŸèƒ½å°†ä¸å¯ç”¨")
    
    @property
    def is_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æœç´¢å¼•æ“"""
        return any(p.is_available for p in self._providers)
    
    def search_stock_news(
        self,
        stock_code: str,
        stock_name: str,
        max_results: int = 5,
        focus_keywords: Optional[List[str]] = None,
        custom_query: Optional[str] = None
    ) -> SearchResponse:
        """
        æœç´¢è‚¡ç¥¨ç›¸å…³æ–°é—»
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
            focus_keywords: é‡ç‚¹å…³æ³¨çš„å…³é”®è¯åˆ—è¡¨ï¼ˆä¼šæ‹¼æ¥åˆ°æŸ¥è¯¢ä¸­ï¼‰
            custom_query: è‡ªå®šä¹‰æŸ¥è¯¢è¯ï¼ˆå¦‚æœæä¾›ï¼Œç›´æ¥ä½¿ç”¨æ­¤æŸ¥è¯¢ï¼‰
            
        Returns:
            SearchResponse å¯¹è±¡
        """
        # å¦‚æœæä¾›äº†è‡ªå®šä¹‰æŸ¥è¯¢ï¼Œç›´æ¥ä½¿ç”¨
        if custom_query:
            query = custom_query
        else:
            # é»˜è®¤é‡ç‚¹å…³æ³¨å…³é”®è¯ï¼ˆåŸºäºäº¤æ˜“ç†å¿µï¼‰
            if focus_keywords is None:
                focus_keywords = [
                    "å¹´æŠ¥é¢„å‘Š", "ä¸šç»©é¢„å‘Š", "ä¸šç»©å¿«æŠ¥",  # ä¸šç»©ç›¸å…³
                    "å‡æŒ", "å¢æŒ", "å›è´­",              # è‚¡ä¸œåŠ¨å‘
                    "æœºæ„è°ƒç ”", "æœºæ„è¯„çº§",              # æœºæ„åŠ¨å‘
                    "åˆ©å¥½", "åˆ©ç©º",                      # æ¶ˆæ¯é¢
                    "åˆåŒ", "è®¢å•", "ä¸­æ ‡",              # ä¸šåŠ¡è¿›å±•
                ]
            
            # æ„å»ºæœç´¢æŸ¥è¯¢
            # å¦‚æœ focus_keywords æ˜¯å®Œæ•´çš„æœç´¢çŸ­è¯­ï¼ˆå¦‚ "Aè‚¡ å¤§ç›˜ ä»Šæ—¥ èµ°åŠ¿åˆ†æ"ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
            if focus_keywords and len(focus_keywords) > 2:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œæ•´çš„æœç´¢çŸ­è¯­ï¼ˆåŒ…å«ç©ºæ ¼æˆ–å¤šä¸ªè¯ï¼‰
                first_keyword = focus_keywords[0] if focus_keywords else ""
                if ' ' in first_keyword or len(focus_keywords) >= 4:
                    # è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„æœç´¢çŸ­è¯­åˆ—è¡¨ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªä½œä¸ºä¸»æŸ¥è¯¢
                    query = ' '.join(focus_keywords[:5])
                else:
                    # ä¼ ç»Ÿæ¨¡å¼ï¼šè‚¡ç¥¨å + å…³é”®è¯
                    query = f"{stock_name} {stock_code} è‚¡ç¥¨ æœ€æ–°æ¶ˆæ¯"
            else:
                query = f"{stock_name} {stock_code} è‚¡ç¥¨ æœ€æ–°æ¶ˆæ¯"
        
        logger.info(f"æœç´¢è‚¡ç¥¨æ–°é—»: {stock_name}({stock_code})")
        
        # ä¾æ¬¡å°è¯•å„ä¸ªæœç´¢å¼•æ“
        for provider in self._providers:
            if not provider.is_available:
                continue
            
            response = provider.search(query, max_results)
            
            if response.success and response.results:
                logger.info(f"ä½¿ç”¨ {provider.name} æœç´¢æˆåŠŸ")
                return response
            else:
                logger.warning(f"{provider.name} æœç´¢å¤±è´¥: {response.error_message}ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå¼•æ“")
        
        # æ‰€æœ‰å¼•æ“éƒ½å¤±è´¥
        return SearchResponse(
            query=query,
            results=[],
            provider="None",
            success=False,
            error_message="æ‰€æœ‰æœç´¢å¼•æ“éƒ½ä¸å¯ç”¨æˆ–æœç´¢å¤±è´¥"
        )
    
    def search_stock_events(
        self,
        stock_code: str,
        stock_name: str,
        event_types: Optional[List[str]] = None
    ) -> SearchResponse:
        """
        æœç´¢è‚¡ç¥¨ç‰¹å®šäº‹ä»¶ï¼ˆå¹´æŠ¥é¢„å‘Šã€å‡æŒç­‰ï¼‰
        
        ä¸“é—¨é’ˆå¯¹äº¤æ˜“å†³ç­–ç›¸å…³çš„é‡è¦äº‹ä»¶è¿›è¡Œæœç´¢
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            event_types: äº‹ä»¶ç±»å‹åˆ—è¡¨
            
        Returns:
            SearchResponse å¯¹è±¡
        """
        if event_types is None:
            event_types = ["å¹´æŠ¥é¢„å‘Š", "å‡æŒå…¬å‘Š", "ä¸šç»©å¿«æŠ¥"]
        
        # æ„å»ºé’ˆå¯¹æ€§æŸ¥è¯¢
        event_query = " OR ".join(event_types)
        query = f"{stock_name} ({event_query})"
        
        logger.info(f"æœç´¢è‚¡ç¥¨äº‹ä»¶: {stock_name}({stock_code}) - {event_types}")
        
        # ä¾æ¬¡å°è¯•å„ä¸ªæœç´¢å¼•æ“
        for provider in self._providers:
            if not provider.is_available:
                continue
            
            response = provider.search(query, max_results=5)
            
            if response.success:
                return response
        
        return SearchResponse(
            query=query,
            results=[],
            provider="None",
            success=False,
            error_message="äº‹ä»¶æœç´¢å¤±è´¥"
        )
    
    def search_comprehensive_intel(
        self,
        stock_code: str,
        stock_name: str,
        max_searches: int = 3
    ) -> Dict[str, SearchResponse]:
        """
        å¤šç»´åº¦æƒ…æŠ¥æœç´¢ï¼ˆåŒæ—¶ä½¿ç”¨å¤šä¸ªå¼•æ“ã€å¤šä¸ªç»´åº¦ï¼‰
        
        æœç´¢ç»´åº¦ï¼š
        1. æœ€æ–°æ¶ˆæ¯ - è¿‘æœŸæ–°é—»åŠ¨æ€
        2. é£é™©æ’æŸ¥ - å‡æŒã€å¤„ç½šã€åˆ©ç©º
        3. ä¸šç»©é¢„æœŸ - å¹´æŠ¥é¢„å‘Šã€ä¸šç»©å¿«æŠ¥
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            max_searches: æœ€å¤§æœç´¢æ¬¡æ•°
            
        Returns:
            {ç»´åº¦åç§°: SearchResponse} å­—å…¸
        """
        results = {}
        search_count = 0
        
        # å®šä¹‰æœç´¢ç»´åº¦
        search_dimensions = [
            {
                'name': 'latest_news',
                'query': f"{stock_name} {stock_code} æœ€æ–° æ–°é—» 2026å¹´1æœˆ",
                'desc': 'æœ€æ–°æ¶ˆæ¯'
            },
            {
                'name': 'risk_check', 
                'query': f"{stock_name} å‡æŒ å¤„ç½š åˆ©ç©º é£é™©",
                'desc': 'é£é™©æ’æŸ¥'
            },
            {
                'name': 'earnings',
                'query': f"{stock_name} å¹´æŠ¥é¢„å‘Š ä¸šç»©é¢„å‘Š ä¸šç»©å¿«æŠ¥ 2025å¹´æŠ¥",
                'desc': 'ä¸šç»©é¢„æœŸ'
            },
        ]
        
        logger.info(f"å¼€å§‹å¤šç»´åº¦æƒ…æŠ¥æœç´¢: {stock_name}({stock_code})")
        
        # è½®æµä½¿ç”¨ä¸åŒçš„æœç´¢å¼•æ“
        provider_index = 0
        
        for dim in search_dimensions:
            if search_count >= max_searches:
                break
            
            # é€‰æ‹©æœç´¢å¼•æ“ï¼ˆè½®æµä½¿ç”¨ï¼‰
            available_providers = [p for p in self._providers if p.is_available]
            if not available_providers:
                break
            
            provider = available_providers[provider_index % len(available_providers)]
            provider_index += 1
            
            logger.info(f"[æƒ…æŠ¥æœç´¢] {dim['desc']}: ä½¿ç”¨ {provider.name}")
            
            response = provider.search(dim['query'], max_results=3)
            results[dim['name']] = response
            search_count += 1
            
            if response.success:
                logger.info(f"[æƒ…æŠ¥æœç´¢] {dim['desc']}: è·å– {len(response.results)} æ¡ç»“æœ")
            else:
                logger.warning(f"[æƒ…æŠ¥æœç´¢] {dim['desc']}: æœç´¢å¤±è´¥ - {response.error_message}")
            
            # çŸ­æš‚å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(0.5)
        
        return results
    
    def format_intel_report(self, intel_results: Dict[str, SearchResponse], stock_name: str) -> str:
        """
        æ ¼å¼åŒ–æƒ…æŠ¥æœç´¢ç»“æœä¸ºæŠ¥å‘Š
        
        Args:
            intel_results: å¤šç»´åº¦æœç´¢ç»“æœ
            stock_name: è‚¡ç¥¨åç§°
            
        Returns:
            æ ¼å¼åŒ–çš„æƒ…æŠ¥æŠ¥å‘Šæ–‡æœ¬
        """
        lines = [f"ã€{stock_name} æƒ…æŠ¥æœç´¢ç»“æœã€‘"]
        
        # æœ€æ–°æ¶ˆæ¯
        if 'latest_news' in intel_results:
            resp = intel_results['latest_news']
            lines.append(f"\nğŸ“° æœ€æ–°æ¶ˆæ¯ (æ¥æº: {resp.provider}):")
            if resp.success and resp.results:
                for i, r in enumerate(resp.results[:3], 1):
                    date_str = f" [{r.published_date}]" if r.published_date else ""
                    lines.append(f"  {i}. {r.title}{date_str}")
                    lines.append(f"     {r.snippet[:100]}...")
            else:
                lines.append("  æœªæ‰¾åˆ°ç›¸å…³æ¶ˆæ¯")
        
        # é£é™©æ’æŸ¥
        if 'risk_check' in intel_results:
            resp = intel_results['risk_check']
            lines.append(f"\nâš ï¸ é£é™©æ’æŸ¥ (æ¥æº: {resp.provider}):")
            if resp.success and resp.results:
                for i, r in enumerate(resp.results[:3], 1):
                    lines.append(f"  {i}. {r.title}")
                    lines.append(f"     {r.snippet[:100]}...")
            else:
                lines.append("  æœªå‘ç°æ˜æ˜¾é£é™©ä¿¡å·")
        
        # ä¸šç»©é¢„æœŸ
        if 'earnings' in intel_results:
            resp = intel_results['earnings']
            lines.append(f"\nğŸ“Š ä¸šç»©é¢„æœŸ (æ¥æº: {resp.provider}):")
            if resp.success and resp.results:
                for i, r in enumerate(resp.results[:3], 1):
                    lines.append(f"  {i}. {r.title}")
                    lines.append(f"     {r.snippet[:100]}...")
            else:
                lines.append("  æœªæ‰¾åˆ°ä¸šç»©ç›¸å…³ä¿¡æ¯")
        
        return "\n".join(lines)
    
    def batch_search(
        self,
        stocks: List[Dict[str, str]],
        max_results_per_stock: int = 3,
        delay_between: float = 1.0
    ) -> Dict[str, SearchResponse]:
        """
        æ‰¹é‡æœç´¢å¤šåªè‚¡ç¥¨æ–°é—»
        
        Args:
            stocks: è‚¡ç¥¨åˆ—è¡¨ [{"code": "300389", "name": "è‰¾æ¯”æ£®"}, ...]
            max_results_per_stock: æ¯åªè‚¡ç¥¨çš„æœ€å¤§ç»“æœæ•°
            delay_between: æ¯æ¬¡æœç´¢ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
            
        Returns:
            {è‚¡ç¥¨ä»£ç : SearchResponse} å­—å…¸
        """
        results = {}
        
        for i, stock in enumerate(stocks):
            if i > 0:
                time.sleep(delay_between)
            
            code = stock.get('code', '')
            name = stock.get('name', '')
            
            response = self.search_stock_news(code, name, max_results_per_stock)
            results[code] = response
        
        return results


# === ä¾¿æ·å‡½æ•° ===
_search_service: Optional[SearchService] = None


def get_search_service() -> SearchService:
    """è·å–æœç´¢æœåŠ¡å•ä¾‹"""
    global _search_service
    
    if _search_service is None:
        from config import get_config
        config = get_config()
        
        _search_service = SearchService(
            bocha_keys=config.bocha_api_keys,
            tavily_keys=config.tavily_api_keys,
            serpapi_keys=config.serpapi_keys,
        )
    
    return _search_service


def reset_search_service() -> None:
    """é‡ç½®æœç´¢æœåŠ¡ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    global _search_service
    _search_service = None


class LLMSearchOptimizer:
    """
    LLM é©±åŠ¨çš„æ™ºèƒ½æœç´¢ä¼˜åŒ–å™¨
    
    åŠŸèƒ½ï¼š
    1. ä½¿ç”¨ LLM ç”Ÿæˆæ›´ç²¾å‡†çš„æœç´¢å…³é”®è¯
    2. æ ¹æ®æœç´¢ç›®çš„ï¼ˆæ¿å—åˆ†æã€ä¸ªè‚¡åˆ†æç­‰ï¼‰å®šåˆ¶æœç´¢ç­–ç•¥
    3. å¯¹æœç´¢ç»“æœè¿›è¡Œæ™ºèƒ½ç­›é€‰å’Œæ‘˜è¦
    """
    
    def __init__(self, analyzer=None):
        """
        åˆå§‹åŒ–æœç´¢ä¼˜åŒ–å™¨
        
        Args:
            analyzer: AI åˆ†æå™¨å®ä¾‹ï¼ˆGeminiAnalyzerï¼‰
        """
        self.analyzer = analyzer
    
    def is_available(self) -> bool:
        """æ£€æŸ¥ LLM æ˜¯å¦å¯ç”¨"""
        return self.analyzer is not None and self.analyzer.is_available()
    
    def generate_sector_search_queries(
        self,
        sector_name: str,
        policy_keywords: List[str],
        search_purpose: str = "catalyst"
    ) -> List[str]:
        """
        ä¸ºæ¿å—åˆ†æç”Ÿæˆæ™ºèƒ½æœç´¢å…³é”®è¯
        
        Args:
            sector_name: æ¿å—åç§°ï¼ˆå¦‚"é“¶è¡Œ"ã€"æˆ¿åœ°äº§"ï¼‰
            policy_keywords: ç›¸å…³æ”¿ç­–å…³é”®è¯
            search_purpose: æœç´¢ç›®çš„
                - "catalyst": å¯»æ‰¾å‚¬åŒ–å‰‚ï¼ˆæ”¿ç­–ã€æŠ€æœ¯çªç ´ï¼‰
                - "risk": é£é™©æ’æŸ¥
                - "reversal": åè½¬ä¿¡å·
            
        Returns:
            ä¼˜åŒ–åçš„æœç´¢å…³é”®è¯åˆ—è¡¨
        """
        if not self.is_available():
            # LLM ä¸å¯ç”¨æ—¶ï¼Œä½¿ç”¨é»˜è®¤å…³é”®è¯
            return self._get_default_queries(sector_name, policy_keywords, search_purpose)
        
        try:
            prompt = self._build_query_generation_prompt(sector_name, policy_keywords, search_purpose)
            
            generation_config = {
                'temperature': 0.3,  # ä½æ¸©åº¦ï¼Œæ›´ç²¾ç¡®
                'max_output_tokens': 500,
            }
            
            response = self.analyzer._call_openai_api(prompt, generation_config)
            
            # è§£æ LLM è¿”å›çš„æœç´¢è¯
            queries = self._parse_query_response(response)
            
            if queries:
                logger.info(f"[LLMæœç´¢ä¼˜åŒ–] ä¸º {sector_name} ç”Ÿæˆ {len(queries)} ä¸ªæœç´¢è¯")
                return queries
            
        except Exception as e:
            logger.warning(f"[LLMæœç´¢ä¼˜åŒ–] ç”Ÿæˆæœç´¢è¯å¤±è´¥: {e}")
        
        # å¤±è´¥æ—¶è¿”å›é»˜è®¤å…³é”®è¯
        return self._get_default_queries(sector_name, policy_keywords, search_purpose)
    
    def _build_query_generation_prompt(
        self,
        sector_name: str,
        policy_keywords: List[str],
        search_purpose: str
    ) -> str:
        """æ„å»ºæœç´¢è¯ç”Ÿæˆçš„ Prompt"""
        
        purpose_desc = {
            "catalyst": "å¯»æ‰¾è¯¥æ¿å—æœªæ¥3-6ä¸ªæœˆçš„å‚¬åŒ–å‰‚ï¼ŒåŒ…æ‹¬ï¼šæ”¿ç­–é¢„æœŸã€æŠ€æœ¯çªç ´ã€äº§å“è½åœ°ã€è¡Œä¸šäº‹ä»¶ç­‰",
            "risk": "æ’æŸ¥è¯¥æ¿å—çš„é£é™©å› ç´ ï¼ŒåŒ…æ‹¬ï¼šæ”¿ç­–åˆ©ç©ºã€è¡Œä¸šå›°å¢ƒã€ä¼°å€¼æ³¡æ²«ã€èµ„é‡‘æµå‡ºç­‰",
            "reversal": "å¯»æ‰¾è¯¥æ¿å—çš„åè½¬ä¿¡å·ï¼ŒåŒ…æ‹¬ï¼šèµ„é‡‘æµå…¥ã€ä¸šç»©æ”¹å–„ã€ä¾›éœ€æ”¹å–„ã€ä¼°å€¼ä¿®å¤ç­‰"
        }
        
        current_month = datetime.now().strftime('%Yå¹´%mæœˆ')
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„Aè‚¡è¡Œä¸šåˆ†æå¸ˆï¼Œè¯·ä¸ºä»¥ä¸‹æ¿å—ç”Ÿæˆç²¾å‡†çš„æœç´¢å…³é”®è¯ã€‚

## ä»»åŠ¡
ä¸º **{sector_name}** æ¿å—ç”Ÿæˆæœç´¢å…³é”®è¯

## æœç´¢ç›®çš„
{purpose_desc.get(search_purpose, purpose_desc['catalyst'])}

## ç›¸å…³æ”¿ç­–å…³é”®è¯ï¼ˆå‚è€ƒï¼‰
{', '.join(policy_keywords) if policy_keywords else 'æ— '}

## å½“å‰æ—¶é—´
{current_month}

## è¦æ±‚
1. ç”Ÿæˆ 3-5 ä¸ªæœç´¢å…³é”®è¯/çŸ­è¯­
2. å…³é”®è¯è¦å…·ä½“ã€ç²¾å‡†ï¼Œèƒ½æœç´¢åˆ°æœ‰ä»·å€¼çš„ä¿¡æ¯
3. åŒ…å«æ—¶é—´é™å®šè¯ï¼ˆå¦‚"2024å¹´"ã€"æœ€æ–°"ã€"è¿‘æœŸ"ï¼‰
4. é’ˆå¯¹ä¸­æ–‡æœç´¢å¼•æ“ä¼˜åŒ–

## è¾“å‡ºæ ¼å¼
è¯·ç›´æ¥è¾“å‡ºæœç´¢å…³é”®è¯ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦ç¼–å·ï¼Œä¸è¦è§£é‡Šï¼š

ç¤ºä¾‹è¾“å‡ºï¼š
é“¶è¡Œ 2024å¹´ å‡€æ¯å·® ä¼ç¨³
é“¶è¡Œè‚¡ é«˜è‚¡æ¯ é™©èµ„å¢æŒ
é“¶è¡Œä¸š åŒ–å€ºæ”¿ç­– èµ„äº§è´¨é‡
"""
        return prompt
    
    def _parse_query_response(self, response: str) -> List[str]:
        """è§£æ LLM è¿”å›çš„æœç´¢è¯"""
        if not response:
            return []
        
        queries = []
        for line in response.strip().split('\n'):
            line = line.strip()
            # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
            if line and not line.startswith('#') and not line.startswith('ç¤ºä¾‹'):
                # ç§»é™¤å¯èƒ½çš„ç¼–å·
                if line[0].isdigit() and '.' in line[:3]:
                    line = line.split('.', 1)[1].strip()
                if line:
                    queries.append(line)
        
        return queries[:5]  # æœ€å¤šè¿”å›5ä¸ª
    
    def _get_default_queries(
        self,
        sector_name: str,
        policy_keywords: List[str],
        search_purpose: str
    ) -> List[str]:
        """è·å–é»˜è®¤æœç´¢å…³é”®è¯ï¼ˆLLM ä¸å¯ç”¨æ—¶ï¼‰"""
        current_year = datetime.now().year
        current_month = datetime.now().strftime('%Yå¹´%mæœˆ')
        
        if search_purpose == "catalyst":
            queries = [
                f"{sector_name} {current_year}å¹´ æ”¿ç­– åˆ©å¥½",
                f"{sector_name} è¡Œä¸š æœ€æ–° åŠ¨æ€ {current_month}",
            ]
            if policy_keywords:
                queries.append(f"{sector_name} {policy_keywords[0]} æœ€æ–°")
        
        elif search_purpose == "risk":
            queries = [
                f"{sector_name} é£é™© åˆ©ç©º {current_year}å¹´",
                f"{sector_name} è¡Œä¸š å›°å¢ƒ é—®é¢˜",
            ]
        
        elif search_purpose == "reversal":
            queries = [
                f"{sector_name} èµ„é‡‘æµå…¥ æœºæ„ {current_month}",
                f"{sector_name} ä¸šç»© æ”¹å–„ å¤è‹",
            ]
        
        else:
            queries = [f"{sector_name} æœ€æ–° æ¶ˆæ¯ {current_month}"]
        
        return queries
    
    def summarize_search_results(
        self,
        results: List[SearchResult],
        sector_name: str,
        summary_purpose: str = "catalyst"
    ) -> Optional[str]:
        """
        ä½¿ç”¨ LLM å¯¹æœç´¢ç»“æœè¿›è¡Œæ™ºèƒ½æ‘˜è¦
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            sector_name: æ¿å—åç§°
            summary_purpose: æ‘˜è¦ç›®çš„
            
        Returns:
            æ™ºèƒ½æ‘˜è¦æ–‡æœ¬
        """
        if not self.is_available() or not results:
            return None
        
        try:
            # æ„å»ºæœç´¢ç»“æœæ–‡æœ¬
            results_text = ""
            for i, r in enumerate(results[:10], 1):
                results_text += f"\n{i}. ã€{r.source}ã€‘{r.title}\n   {r.snippet[:200]}\n"
            
            purpose_desc = {
                "catalyst": "æå–å¯¹è¯¥æ¿å—æœ‰åˆ©çš„å‚¬åŒ–å‰‚ä¿¡æ¯ï¼ˆæ”¿ç­–ã€æŠ€æœ¯ã€äº‹ä»¶ï¼‰",
                "risk": "æå–è¯¥æ¿å—é¢ä¸´çš„é£é™©å’Œåˆ©ç©ºå› ç´ ",
                "reversal": "æå–è¯¥æ¿å—å¯èƒ½åè½¬çš„ä¿¡å·"
            }
            
            prompt = f"""è¯·åˆ†æä»¥ä¸‹å…³äº **{sector_name}** æ¿å—çš„æœç´¢ç»“æœï¼Œ{purpose_desc.get(summary_purpose, '')}ã€‚

## æœç´¢ç»“æœ
{results_text}

## è¦æ±‚
1. æå–æœ€é‡è¦çš„ 2-3 æ¡ä¿¡æ¯
2. ç”¨ç®€æ´çš„è¯­è¨€æ€»ç»“
3. æ ‡æ³¨ä¿¡æ¯æ¥æº
4. å¦‚æœæ²¡æœ‰æœ‰ä»·å€¼çš„ä¿¡æ¯ï¼Œç›´æ¥è¯´"æœªå‘ç°æœ‰ä»·å€¼ä¿¡æ¯"

## è¾“å‡ºæ ¼å¼
ç›´æ¥è¾“å‡ºæ‘˜è¦ï¼Œä¸è¶…è¿‡ 200 å­—ã€‚
"""
            
            generation_config = {
                'temperature': 0.3,
                'max_output_tokens': 300,
            }
            
            summary = self.analyzer._call_openai_api(prompt, generation_config)
            return summary.strip() if summary else None
            
        except Exception as e:
            logger.warning(f"[LLMæœç´¢ä¼˜åŒ–] æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            return None


class SmartSearchService(SearchService):
    """
    æ™ºèƒ½æœç´¢æœåŠ¡ï¼ˆç»§æ‰¿è‡ª SearchServiceï¼Œå¢åŠ  LLM ä¼˜åŒ–èƒ½åŠ›ï¼‰
    
    åŠŸèƒ½ï¼š
    1. ç»§æ‰¿åŸºç¡€æœç´¢èƒ½åŠ›
    2. ä½¿ç”¨ LLM ä¼˜åŒ–æœç´¢å…³é”®è¯
    3. å¯¹æœç´¢ç»“æœè¿›è¡Œæ™ºèƒ½ç­›é€‰å’Œæ‘˜è¦
    4. ä¸“é—¨é’ˆå¯¹æ¿å—åŸ‹ä¼åˆ†æä¼˜åŒ–
    """
    
    def __init__(
        self,
        bocha_keys: Optional[List[str]] = None,
        tavily_keys: Optional[List[str]] = None,
        serpapi_keys: Optional[List[str]] = None,
        analyzer=None
    ):
        """
        åˆå§‹åŒ–æ™ºèƒ½æœç´¢æœåŠ¡
        
        Args:
            bocha_keys: åšæŸ¥æœç´¢ API Key åˆ—è¡¨
            tavily_keys: Tavily API Key åˆ—è¡¨
            serpapi_keys: SerpAPI Key åˆ—è¡¨
            analyzer: AI åˆ†æå™¨å®ä¾‹ï¼ˆç”¨äº LLM ä¼˜åŒ–ï¼‰
        """
        super().__init__(bocha_keys, tavily_keys, serpapi_keys)
        self.optimizer = LLMSearchOptimizer(analyzer)
        
        if self.optimizer.is_available():
            logger.info("æ™ºèƒ½æœç´¢æœåŠ¡å·²å¯ç”¨ LLM ä¼˜åŒ–")
    
    def search_sector_catalyst(
        self,
        sector_name: str,
        policy_keywords: Optional[List[str]] = None,
        max_results: int = 5,
        use_llm: bool = True
    ) -> Dict[str, Any]:
        """
        æœç´¢æ¿å—å‚¬åŒ–å‰‚ä¿¡æ¯
        
        ä¸“é—¨ç”¨äºæ¿å—åŸ‹ä¼åˆ†æï¼Œå¯»æ‰¾æ”¿ç­–ã€æŠ€æœ¯ã€äº‹ä»¶ç­‰å‚¬åŒ–å‰‚
        
        Args:
            sector_name: æ¿å—åç§°
            policy_keywords: ç›¸å…³æ”¿ç­–å…³é”®è¯
            max_results: æœ€å¤§ç»“æœæ•°
            use_llm: æ˜¯å¦ä½¿ç”¨ LLM ä¼˜åŒ–
            
        Returns:
            {
                'queries': ä½¿ç”¨çš„æœç´¢è¯åˆ—è¡¨,
                'results': æœç´¢ç»“æœåˆ—è¡¨,
                'summary': LLM æ‘˜è¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰,
                'success': æ˜¯å¦æˆåŠŸ
            }
        """
        policy_keywords = policy_keywords or []
        
        # ç”Ÿæˆæœç´¢å…³é”®è¯
        if use_llm and self.optimizer.is_available():
            queries = self.optimizer.generate_sector_search_queries(
                sector_name, policy_keywords, "catalyst"
            )
        else:
            queries = self.optimizer._get_default_queries(
                sector_name, policy_keywords, "catalyst"
            )
        
        logger.info(f"[æ™ºèƒ½æœç´¢] æ¿å—å‚¬åŒ–å‰‚æœç´¢: {sector_name}, å…³é”®è¯: {queries}")
        
        # æ‰§è¡Œæœç´¢
        all_results = []
        for query in queries[:3]:  # æœ€å¤šæœç´¢3æ¬¡
            response = self._search_with_fallback(query, max_results=3)
            if response.success and response.results:
                all_results.extend(response.results)
            time.sleep(0.3)  # é¿å…è¯·æ±‚è¿‡å¿«
        
        # å»é‡
        seen_urls = set()
        unique_results = []
        for r in all_results:
            if r.url not in seen_urls:
                seen_urls.add(r.url)
                unique_results.append(r)
        
        # LLM æ‘˜è¦
        summary = None
        if use_llm and unique_results:
            summary = self.optimizer.summarize_search_results(
                unique_results, sector_name, "catalyst"
            )
        
        return {
            'queries': queries,
            'results': unique_results[:max_results],
            'summary': summary,
            'success': len(unique_results) > 0
        }
    
    def search_sector_risks(
        self,
        sector_name: str,
        max_results: int = 5,
        use_llm: bool = True
    ) -> Dict[str, Any]:
        """
        æœç´¢æ¿å—é£é™©ä¿¡æ¯
        
        Args:
            sector_name: æ¿å—åç§°
            max_results: æœ€å¤§ç»“æœæ•°
            use_llm: æ˜¯å¦ä½¿ç”¨ LLM ä¼˜åŒ–
            
        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        # ç”Ÿæˆæœç´¢å…³é”®è¯
        if use_llm and self.optimizer.is_available():
            queries = self.optimizer.generate_sector_search_queries(
                sector_name, [], "risk"
            )
        else:
            queries = self.optimizer._get_default_queries(sector_name, [], "risk")
        
        logger.info(f"[æ™ºèƒ½æœç´¢] æ¿å—é£é™©æœç´¢: {sector_name}, å…³é”®è¯: {queries}")
        
        # æ‰§è¡Œæœç´¢
        all_results = []
        for query in queries[:2]:
            response = self._search_with_fallback(query, max_results=3)
            if response.success and response.results:
                all_results.extend(response.results)
            time.sleep(0.3)
        
        # å»é‡
        seen_urls = set()
        unique_results = []
        for r in all_results:
            if r.url not in seen_urls:
                seen_urls.add(r.url)
                unique_results.append(r)
        
        # LLM æ‘˜è¦
        summary = None
        if use_llm and unique_results:
            summary = self.optimizer.summarize_search_results(
                unique_results, sector_name, "risk"
            )
        
        return {
            'queries': queries,
            'results': unique_results[:max_results],
            'summary': summary,
            'success': len(unique_results) > 0
        }
    
    def search_market_policy(
        self,
        focus_areas: Optional[List[str]] = None,
        max_results: int = 10,
        use_llm: bool = True
    ) -> Dict[str, Any]:
        """
        æœç´¢å¸‚åœºæ”¿ç­–å’Œå®è§‚ä¿¡æ¯
        
        ç”¨äºå¤§ç›˜å¤ç›˜åˆ†æï¼Œè·å–æœ€æ–°çš„æ”¿ç­–åŠ¨å‘
        
        Args:
            focus_areas: é‡ç‚¹å…³æ³¨é¢†åŸŸï¼ˆå¦‚["æˆ¿åœ°äº§", "ç§‘æŠ€", "é‡‘è"]ï¼‰
            max_results: æœ€å¤§ç»“æœæ•°
            use_llm: æ˜¯å¦ä½¿ç”¨ LLM ä¼˜åŒ–
            
        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        current_month = datetime.now().strftime('%Yå¹´%mæœˆ')
        
        # é»˜è®¤å…³æ³¨é¢†åŸŸ
        if focus_areas is None:
            focus_areas = ["å®è§‚ç»æµ", "è´§å¸æ”¿ç­–", "äº§ä¸šæ”¿ç­–"]
        
        # ç”Ÿæˆæœç´¢å…³é”®è¯
        if use_llm and self.optimizer.is_available():
            queries = self._generate_policy_queries_with_llm(focus_areas)
        else:
            queries = [
                f"Aè‚¡ æ”¿ç­– åˆ©å¥½ {current_month}",
                f"å¤®è¡Œ è´§å¸æ”¿ç­– æœ€æ–° {current_month}",
                f"äº§ä¸šæ”¿ç­– æ‰¶æŒ {current_month}",
            ]
        
        logger.info(f"[æ™ºèƒ½æœç´¢] å¸‚åœºæ”¿ç­–æœç´¢, å…³é”®è¯: {queries}")
        
        # æ‰§è¡Œæœç´¢
        all_results = []
        for query in queries[:4]:
            response = self._search_with_fallback(query, max_results=3)
            if response.success and response.results:
                all_results.extend(response.results)
            time.sleep(0.3)
        
        # å»é‡
        seen_urls = set()
        unique_results = []
        for r in all_results:
            if r.url not in seen_urls:
                seen_urls.add(r.url)
                unique_results.append(r)
        
        return {
            'queries': queries,
            'results': unique_results[:max_results],
            'success': len(unique_results) > 0
        }
    
    def _generate_policy_queries_with_llm(self, focus_areas: List[str]) -> List[str]:
        """ä½¿ç”¨ LLM ç”Ÿæˆæ”¿ç­–æœç´¢å…³é”®è¯"""
        if not self.optimizer.is_available():
            return []
        
        try:
            current_month = datetime.now().strftime('%Yå¹´%mæœˆ')
            
            prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„Aè‚¡å¸‚åœºåˆ†æå¸ˆï¼Œè¯·ç”Ÿæˆæœç´¢å…³é”®è¯æ¥è·å–æœ€æ–°çš„å¸‚åœºæ”¿ç­–ä¿¡æ¯ã€‚

## é‡ç‚¹å…³æ³¨é¢†åŸŸ
{', '.join(focus_areas)}

## å½“å‰æ—¶é—´
{current_month}

## è¦æ±‚
1. ç”Ÿæˆ 4 ä¸ªæœç´¢å…³é”®è¯
2. å…³é”®è¯è¦èƒ½æœç´¢åˆ°æœ€æ–°çš„æ”¿ç­–åŠ¨å‘ã€ç›‘ç®¡ä¿¡æ¯ã€å®è§‚ç»æµæ•°æ®
3. åŒ…å«æ—¶é—´é™å®šè¯

## è¾“å‡ºæ ¼å¼
æ¯è¡Œä¸€ä¸ªå…³é”®è¯ï¼Œä¸è¦ç¼–å·ï¼š
"""
            
            generation_config = {
                'temperature': 0.3,
                'max_output_tokens': 200,
            }
            
            response = self.optimizer.analyzer._call_openai_api(prompt, generation_config)
            return self.optimizer._parse_query_response(response)
            
        except Exception as e:
            logger.warning(f"[æ™ºèƒ½æœç´¢] ç”Ÿæˆæ”¿ç­–æœç´¢è¯å¤±è´¥: {e}")
            return []
    
    def _search_with_fallback(self, query: str, max_results: int = 5) -> SearchResponse:
        """å¸¦æ•…éšœè½¬ç§»çš„æœç´¢"""
        for provider in self._providers:
            if not provider.is_available:
                continue
            
            response = provider.search(query, max_results)
            if response.success and response.results:
                return response
        
        return SearchResponse(
            query=query,
            results=[],
            provider="None",
            success=False,
            error_message="æ‰€æœ‰æœç´¢å¼•æ“éƒ½ä¸å¯ç”¨"
        )
    
    def search_sector_comprehensive(
        self,
        sector_name: str,
        policy_keywords: Optional[List[str]] = None,
        use_llm: bool = True
    ) -> Dict[str, Any]:
        """
        æ¿å—ç»¼åˆæœç´¢ï¼ˆå‚¬åŒ–å‰‚ + é£é™© + åè½¬ä¿¡å·ï¼‰
        
        ä¸“é—¨ä¸ºæ¿å—åŸ‹ä¼åˆ†æè®¾è®¡çš„ç»¼åˆæœç´¢
        
        Args:
            sector_name: æ¿å—åç§°
            policy_keywords: ç›¸å…³æ”¿ç­–å…³é”®è¯
            use_llm: æ˜¯å¦ä½¿ç”¨ LLM ä¼˜åŒ–
            
        Returns:
            {
                'catalyst': å‚¬åŒ–å‰‚æœç´¢ç»“æœ,
                'risk': é£é™©æœç´¢ç»“æœ,
                'combined_summary': ç»¼åˆæ‘˜è¦
            }
        """
        policy_keywords = policy_keywords or []
        
        logger.info(f"[æ™ºèƒ½æœç´¢] å¼€å§‹æ¿å—ç»¼åˆæœç´¢: {sector_name}")
        
        # 1. æœç´¢å‚¬åŒ–å‰‚
        catalyst_result = self.search_sector_catalyst(
            sector_name, policy_keywords, max_results=5, use_llm=use_llm
        )
        
        # 2. æœç´¢é£é™©
        risk_result = self.search_sector_risks(
            sector_name, max_results=3, use_llm=use_llm
        )
        
        # 3. ç”Ÿæˆç»¼åˆæ‘˜è¦
        combined_summary = None
        if use_llm and self.optimizer.is_available():
            combined_summary = self._generate_combined_summary(
                sector_name, catalyst_result, risk_result
            )
        
        return {
            'sector_name': sector_name,
            'catalyst': catalyst_result,
            'risk': risk_result,
            'combined_summary': combined_summary
        }
    
    def _generate_combined_summary(
        self,
        sector_name: str,
        catalyst_result: Dict[str, Any],
        risk_result: Dict[str, Any]
    ) -> Optional[str]:
        """ç”Ÿæˆç»¼åˆæ‘˜è¦"""
        if not self.optimizer.is_available():
            return None
        
        try:
            # æ„å»ºè¾“å…¥
            catalyst_text = ""
            if catalyst_result.get('results'):
                for r in catalyst_result['results'][:5]:
                    catalyst_text += f"- {r.title}: {r.snippet[:100]}\n"
            
            risk_text = ""
            if risk_result.get('results'):
                for r in risk_result['results'][:3]:
                    risk_text += f"- {r.title}: {r.snippet[:100]}\n"
            
            prompt = f"""è¯·ä¸º **{sector_name}** æ¿å—ç”ŸæˆåŸ‹ä¼åˆ†ææ‘˜è¦ã€‚

## å‚¬åŒ–å‰‚ä¿¡æ¯
{catalyst_text if catalyst_text else 'æœªæœç´¢åˆ°ç›¸å…³ä¿¡æ¯'}

## é£é™©ä¿¡æ¯
{risk_text if risk_text else 'æœªæœç´¢åˆ°æ˜æ˜¾é£é™©'}

## è¦æ±‚
1. ç”¨ 2-3 å¥è¯æ€»ç»“è¯¥æ¿å—çš„åŸ‹ä¼ä»·å€¼
2. æ˜ç¡®æŒ‡å‡ºä¸»è¦å‚¬åŒ–å‰‚å’Œé£é™©ç‚¹
3. ç»™å‡ºæ˜¯å¦å€¼å¾—åŸ‹ä¼çš„åˆæ­¥åˆ¤æ–­

## è¾“å‡ºæ ¼å¼
ç›´æ¥è¾“å‡ºæ‘˜è¦ï¼Œä¸è¶…è¿‡ 150 å­—ã€‚
"""
            
            generation_config = {
                'temperature': 0.3,
                'max_output_tokens': 200,
            }
            
            summary = self.optimizer.analyzer._call_openai_api(prompt, generation_config)
            return summary.strip() if summary else None
            
        except Exception as e:
            logger.warning(f"[æ™ºèƒ½æœç´¢] ç”Ÿæˆç»¼åˆæ‘˜è¦å¤±è´¥: {e}")
            return None


if __name__ == "__main__":
    # æµ‹è¯•æœç´¢æœåŠ¡
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s | %(levelname)-8s | %(name)-20s | %(message)s'
    )
    
    # æ‰‹åŠ¨æµ‹è¯•ï¼ˆéœ€è¦é…ç½® API Keyï¼‰
    service = get_search_service()
    
    if service.is_available:
        print("=== æµ‹è¯•è‚¡ç¥¨æ–°é—»æœç´¢ ===")
        response = service.search_stock_news("300389", "è‰¾æ¯”æ£®")
        print(f"æœç´¢çŠ¶æ€: {'æˆåŠŸ' if response.success else 'å¤±è´¥'}")
        print(f"æœç´¢å¼•æ“: {response.provider}")
        print(f"ç»“æœæ•°é‡: {len(response.results)}")
        print(f"è€—æ—¶: {response.search_time:.2f}s")
        print("\n" + response.to_context())
    else:
        print("æœªé…ç½®æœç´¢å¼•æ“ API Keyï¼Œè·³è¿‡æµ‹è¯•")
